{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "intro",
    "description": "Introduction to building RAG with GoodMem",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "# Building a Basic RAG Agent with GoodMem\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial will guide you through building a complete **Retrieval-Augmented Generation (RAG)** system using GoodMem's vector memory capabilities. By the end of this guide, you'll have a functional Q&A system that can:\n",
    "\n",
    "- \ud83d\udd0d **Semantically search** through your documents\n",
    "- \ud83d\udcdd **Generate contextual answers** using retrieved information \n",
    "- \ud83c\udfd7\ufe0f **Scale to handle** large document collections\n",
    "\n",
    "### What is RAG?\n",
    "\n",
    "RAG combines the power of **retrieval** (finding relevant information) with **generation** (creating natural language responses). This approach allows AI systems to provide accurate, context-aware answers by:\n",
    "\n",
    "1. **Retrieving** relevant documents from a knowledge base\n",
    "2. **Augmenting** the query with this context\n",
    "3. **Generating** a comprehensive answer using both the query and retrieved information\n",
    "\n",
    "### Why GoodMem for RAG?\n",
    "\n",
    "GoodMem provides enterprise-grade vector storage with:\n",
    "- **Multiple embedder support** for optimal retrieval accuracy\n",
    "- **Streaming APIs** for real-time responses\n",
    "- **Advanced post-processing** with reranking and summarization\n",
    "- **Scalable architecture** for production workloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "prerequisites",
    "description": "Prerequisites for Go tutorial",
    "language_dependent": true,
    "notebook": "go"
   },
   "source": "## Prerequisites\n\nBefore starting, ensure you have:\n\n- \u2705 **GoodMem server running** (install with: `curl -s https://get.goodmem.ai | bash`)\n- \u2705 **Go 1.18+** installed\n- \u2705 **API key** for your GoodMem instance\n- \u2705 **OpenAI API key** (for embedder and LLM in complete RAG demo)\n- \u2705 **Voyage AI API key** (for reranker in complete RAG demo)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "installation-header",
    "description": "Installation and setup header",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Installation & Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "pre-installation",
    "description": "Configure Go environment variables and install GoodMem SDK",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: GOPROXY=\"https://go-proxy.fury.io/weisi/\"\n",
      "Set: GOPRIVATE=\"github.com/PAIR-Systems-Inc/goodmem\"\n",
      "Set: GOSUMDB=\"off\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "go: added github.com/PAIR-Systems-Inc/goodmem/clients/go v1.0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module gonb_a94ab2e3\n",
      "\n",
      "go 1.25.5\n",
      "\n",
      "require github.com/PAIR-Systems-Inc/goodmem/clients/go v1.0.25 // indirect\n"
     ]
    }
   ],
   "source": [
    "// Fix for import\n",
    "%env GOPROXY=\"https://go-proxy.fury.io/weisi/\"\n",
    "%env GOPRIVATE=\"github.com/PAIR-Systems-Inc/goodmem\"\n",
    "%env GOSUMDB=off\n",
    "!* go get github.com/PAIR-Systems-Inc/goodmem/clients/go@v1.0.25\n",
    "!*cat go.mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "installation",
    "description": "Go imports and helper functions",
    "notebook": "go"
   },
   "outputs": [],
   "source": [
    "import (\n",
    "    \"context\"\n",
    "    \"fmt\"\n",
    "    \"log\"\n",
    "    \"os\"\n",
    "    \"time\"\n",
    "    \"github.com/janpfeifer/gonb/cache\"    // Used by gonb to persist variables across cells\n",
    "    goodmem_client \"github.com/PAIR-Systems-Inc/goodmem/clients/go\"\n",
    ")\n",
    "\n",
    "// Helper functions for pointer creation\n",
    "func PtrInt32(v int32) *int32 { return &v }\n",
    "func PtrBool(v bool) *bool    { return &v }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "auth-header",
    "description": "Authentication and configuration explanation",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Authentication & Configuration\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "GoodMem uses API key authentication to secure your vector memory data. Proper configuration ensures:\n",
    "- **Secure access** to your GoodMem instance\n",
    "- **Isolated environments** (development, staging, production)\n",
    "- **Usage tracking** and access control per API key\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Configure the GoodMem host URL (where your server is running)\n",
    "2. Set up API key authentication\n",
    "3. Verify the configuration is correct\n",
    "\n",
    "### Configuration Options\n",
    "\n",
    "- **Local development**: `http://localhost:8080` (default)\n",
    "- **Remote/production**: Your deployed GoodMem URL\n",
    "- **Environment variables**: Best practice for managing credentials\n",
    "\n",
    "Let's configure our GoodMem client and test the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "env-setup",
    "description": "Configure GoodMem API client with authentication",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoodMem Host: localhost:8080\n",
      "API Key configured: Yes\n"
     ]
    }
   ],
   "source": [
    "// Configuration - Update these values for your setup\n",
    "var (\n",
    "    GOODMEM_HOST    = getEnv(\"GOODMEM_HOST\", \"localhost:8080\")\n",
    "    GOODMEM_API_KEY = getEnv(\"GOODMEM_API_KEY\", \"\")\n",
    ")\n",
    "\n",
    "func getEnv(key, defaultValue string) string {\n",
    "    if value := os.Getenv(key); value != \"\" {\n",
    "        return value\n",
    "    }\n",
    "    return defaultValue\n",
    "}\n",
    "\n",
    "%%\n",
    "fmt.Printf(\"GoodMem Host: %s\\n\", GOODMEM_HOST)\n",
    "if GOODMEM_API_KEY == \"your-api-key-here\" {\n",
    "    fmt.Println(\"API Key configured: No - Please update\")\n",
    "} else {\n",
    "    fmt.Println(\"API Key configured: Yes\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "test-connection",
    "description": "Test connection to GoodMem server",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Successfully connected to GoodMem!\n",
      "   Found 0 existing spaces\n"
     ]
    }
   ],
   "source": [
    "// Create GoodMem API client\n",
    "func getClient() *goodmem_client.APIClient {\n",
    "    configuration := goodmem_client.NewConfiguration()\n",
    "    configuration.Host = GOODMEM_HOST\n",
    "    configuration.Scheme = \"http\"\n",
    "    configuration.DefaultHeader[\"X-API-Key\"] = GOODMEM_API_KEY\n",
    "    client := goodmem_client.NewAPIClient(configuration)\n",
    "    return client\n",
    "}\n",
    "\n",
    "%%\n",
    "client := getClient()\n",
    "ctx := context.Background()\n",
    "// Test connection by listing spaces\n",
    "listResponse, httpResp, err := client.SpacesAPI.ListSpaces(ctx).Execute()\n",
    "if err != nil {\n",
    "    log.Fatalf(\"\u274c Error connecting to GoodMem: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "}\n",
    "\n",
    "fmt.Println(\"\u2705 Successfully connected to GoodMem!\")\n",
    "if listResponse.Spaces != nil {\n",
    "    fmt.Printf(\"   Found %d existing spaces\\n\", len(listResponse.Spaces))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "embedder-header",
    "description": "Embedder explanation and concepts",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Creating an Embedder\n",
    "\n",
    "### Why Embedders Matter\n",
    "\n",
    "An **embedder** is the foundation of semantic search. It converts text into high-dimensional vectors (embeddings) that capture meaning:\n",
    "\n",
    "```\n",
    "Text: \"vacation policy\" \u2192 Vector: [0.23, -0.45, 0.67, ...]  (1536 dimensions)\n",
    "```\n",
    "\n",
    "These vectors enable:\n",
    "- **Semantic similarity**: Find conceptually similar content, not just keyword matches\n",
    "- **Context understanding**: Capture meaning beyond exact word matches\n",
    "- **Efficient retrieval**: Fast vector comparisons using specialized indexes\n",
    "\n",
    "### The RAG Pipeline Flow\n",
    "\n",
    "```\n",
    "Documents \u2192 Embedder \u2192 Vector Storage \u2192 Semantic Search \u2192 Retrieved Context\n",
    "```\n",
    "\n",
    "### Choosing an Embedder\n",
    "\n",
    "**OpenAI `text-embedding-3-small`** (what we'll use):\n",
    "- \u2705 **High quality**: Excellent for most use cases\n",
    "- \u2705 **Fast**: Low latency for real-time applications  \n",
    "- \u2705 **1536 dimensions**: Good balance of quality and storage\n",
    "- \u2705 **Cost-effective**: $0.02 per 1M tokens\n",
    "\n",
    "**Other options**:\n",
    "- **text-embedding-3-large**: Higher quality, 3072 dimensions, more expensive\n",
    "- **Voyage AI**: Specialized for search, excellent retrieval performance\n",
    "- **Cohere**: Good multilingual support\n",
    "- **Local models**: HuggingFace sentence transformers for privacy/offline\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Check if an embedder already exists\n",
    "2. If not, create an OpenAI embedder with proper authentication\n",
    "3. Verify the embedder is ready for use\n",
    "\n",
    "**Note**: You'll need an OpenAI API key set in your environment variable `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "create-embedder",
    "description": "Create OpenAI text-embedding-3-small embedder",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Creating new OpenAI text-embedding-3-small embedder...\n",
      "\u2705 Successfully created OpenAI embedder\n",
      "   Display Name: OpenAI Text Embedding 3 Small\n",
      "   Embedder ID: 258ede3c-af3a-4e8e-87e1-87f5ff9a64be\n",
      "   Model: text-embedding-3-small\n",
      "   Dimensionality: 1536\n"
     ]
    }
   ],
   "source": [
    "// Create OpenAI text-embedding-3-small embedder\n",
    "func createOpenAIEmbedder() string {\n",
    "    openaiApiKey := getEnv(\"OPENAI_API_KEY\", \"\")\n",
    "    if openaiApiKey == \"\" {\n",
    "        fmt.Println(\"\u26a0\ufe0f  OPENAI_API_KEY environment variable not set\")\n",
    "        fmt.Println(\"   Please set your OpenAI API key to create an embedder\")\n",
    "        return \"\"\n",
    "    }\n",
    "    \n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    \n",
    "    // Check if embedder already exists\n",
    "    existingEmbedders, _, _ := client.EmbeddersAPI.ListEmbedders(ctx).Execute()\n",
    "    for _, embedder := range existingEmbedders.Embedders {\n",
    "        if embedder.ProviderType == \"OPENAI\" && embedder.ModelIdentifier == \"text-embedding-3-small\" {\n",
    "            fmt.Printf(\"\u2705 OpenAI embedder already exists\\n\")\n",
    "            fmt.Printf(\"   Display Name: %s\\n\", embedder.DisplayName)\n",
    "            fmt.Printf(\"   Embedder ID: %s\\n\", embedder.EmbedderId)\n",
    "            fmt.Printf(\"   Model: %s\\n\", embedder.ModelIdentifier)\n",
    "            fmt.Printf(\"   Dimensionality: %d\\n\", embedder.Dimensionality)\n",
    "            return embedder.EmbedderId\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Create new embedder\n",
    "    fmt.Println(\"\ud83d\udcdd Creating new OpenAI text-embedding-3-small embedder...\")\n",
    "    \n",
    "    // Create string variables for NullableString fields\n",
    "    headerName := \"Authorization\"\n",
    "    prefix := \"Bearer \"\n",
    "    apiPath := \"/embeddings\"\n",
    "    \n",
    "    credentials := goodmem_client.EndpointAuthentication{\n",
    "        Kind: goodmem_client.CREDENTIAL_KIND_API_KEY,\n",
    "        ApiKey: &goodmem_client.ApiKeyAuth{\n",
    "            InlineSecret: *goodmem_client.NewNullableString(&openaiApiKey),\n",
    "            HeaderName:   *goodmem_client.NewNullableString(&headerName),\n",
    "            Prefix:       *goodmem_client.NewNullableString(&prefix),\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    embedderRequest := goodmem_client.EmbedderCreationRequest{\n",
    "        DisplayName:         \"OpenAI Text Embedding 3 Small\",\n",
    "        ProviderType:        \"OPENAI\",\n",
    "        EndpointUrl:         \"https://api.openai.com/v1\",\n",
    "        ModelIdentifier:     \"text-embedding-3-small\",\n",
    "        Dimensionality:      1536,\n",
    "        ApiPath:             *goodmem_client.NewNullableString(&apiPath),\n",
    "        DistributionType:    goodmem_client.DistributionType(\"DENSE\"),\n",
    "        SupportedModalities: []goodmem_client.Modality{goodmem_client.Modality(\"TEXT\")},\n",
    "        Credentials:         &credentials,\n",
    "    }\n",
    "    \n",
    "    newEmbedder, httpResp, err := client.EmbeddersAPI.CreateEmbedder(ctx).EmbedderCreationRequest(embedderRequest).Execute()\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"\u274c Failed to create embedder: %v (HTTP Status: %d)\\n\", err, httpResp.StatusCode)\n",
    "        return \"\"\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"\u2705 Successfully created OpenAI embedder\\n\")\n",
    "    fmt.Printf(\"   Display Name: %s\\n\", newEmbedder.DisplayName)\n",
    "    fmt.Printf(\"   Embedder ID: %s\\n\", newEmbedder.EmbedderId)\n",
    "    fmt.Printf(\"   Model: %s\\n\", newEmbedder.ModelIdentifier)\n",
    "    fmt.Printf(\"   Dimensionality: %d\\n\", newEmbedder.Dimensionality)\n",
    "    \n",
    "    return newEmbedder.EmbedderId\n",
    "}\n",
    "\n",
    "%%\n",
    "createOpenAIEmbedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "space-header",
    "description": "Space concept and chunking explanation",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Creating Your First Space\n",
    "\n",
    "### What is a Space?\n",
    "\n",
    "A **Space** in GoodMem is a logical container for organizing related memories (documents). Think of it as a database or collection where you store and retrieve semantically similar content.\n",
    "\n",
    "Each space has:\n",
    "- **Associated embedders**: Which models convert text to vectors\n",
    "- **Chunking configuration**: How documents are split into searchable pieces\n",
    "- **Access controls**: Public or private, with permission management\n",
    "- **Metadata labels**: For organization and filtering\n",
    "\n",
    "### Use Cases for Multiple Spaces\n",
    "\n",
    "You might create different spaces for:\n",
    "- **By domain**: Technical docs, HR policies, product specs\n",
    "- **By environment**: Development, staging, production\n",
    "- **By customer**: Tenant-specific data in multi-tenant apps\n",
    "- **By privacy level**: Public FAQ vs. internal knowledge base\n",
    "\n",
    "### Why Chunking Matters\n",
    "\n",
    "Documents are too large to search efficiently as whole units. Chunking:\n",
    "- **Improves relevance**: Match specific sections, not entire documents\n",
    "- **Enables context**: Return focused chunks that answer specific questions  \n",
    "- **Optimizes retrieval**: Process and compare smaller text segments\n",
    "\n",
    "**Our chunking strategy**:\n",
    "- **256 characters**: Short enough for focused context, long enough for meaning\n",
    "- **25 character overlap**: Ensures concepts spanning chunk boundaries aren't lost\n",
    "- **Hierarchical separators**: Split on paragraphs first, then sentences, then words\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. List available embedders\n",
    "2. Create a space with our embedder and chunking configuration\n",
    "3. Add metadata labels for organization\n",
    "4. Verify the space is ready\n",
    "\n",
    "Let's create a space for our RAG demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "list-embedders",
    "description": "List available embedders",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udccb Available Embedders (1):\n",
      "   1. OpenAI Text Embedding 3 Small - OPENAI\n",
      "      Model: text-embedding-3-small\n",
      "      ID: 258ede3c-af3a-4e8e-87e1-87f5ff9a64be\n",
      "\n",
      "\ud83c\udfaf Using embedder: OpenAI Text Embedding 3 Small\n"
     ]
    }
   ],
   "source": [
    "// First, let's see what embedders are available\n",
    "func getEmbedders() []goodmem_client.EmbedderResponse {\n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    \n",
    "    listResponse, httpResp, err := client.EmbeddersAPI.ListEmbedders(ctx).Execute()\n",
    "    if err != nil {\n",
    "        log.Fatalf(\"\u274c Error connecting to GoodMem: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "    }\n",
    "    return listResponse.Embedders\n",
    "}\n",
    "\n",
    "%%\n",
    "availableEmbedders := getEmbedders()\n",
    "fmt.Printf(\"\ud83d\udccb Available Embedders (%d):\\n\", len(availableEmbedders))\n",
    "for i, embedder := range availableEmbedders {\n",
    "    fmt.Printf(\"   %d. %s - %s\\n\", i+1, embedder.DisplayName, embedder.ProviderType)\n",
    "    fmt.Printf(\"      Model: %s\\n\", embedder.ModelIdentifier)\n",
    "    fmt.Printf(\"      ID: %s\\n\", embedder.EmbedderId)\n",
    "    fmt.Println()\n",
    "}\n",
    "\n",
    "var defaultEmbedder *goodmem_client.EmbedderResponse\n",
    "if len(availableEmbedders) > 0 {\n",
    "    defaultEmbedder = &availableEmbedders[0]\n",
    "    fmt.Printf(\"\ud83c\udfaf Using embedder: %s\\n\", defaultEmbedder.DisplayName)\n",
    "} else {\n",
    "    fmt.Println(\"\u26a0\ufe0f  No embedders found. You may need to configure an embedder first.\")\n",
    "    fmt.Println(\"   Refer to the documentation: https://docs.goodmem.ai/docs/reference/cli/goodmem_embedder_create/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "cache-reset-space",
    "description": "Reset gonb cache for demoSpaceId variable",
    "notebook": "go"
   },
   "outputs": [],
   "source": [
    "// Execute to clear gonb cache on demoSpaceId\n",
    "%%\n",
    "cache.ResetKey(\"demoSpaceId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "create-space",
    "description": "Create space with chunking configuration",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Created space: RAG Demo Knowledge Base (Go)\n",
      "   Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "   Embedders: 1\n",
      "   Labels: map[content-type:documentation environment:tutorial purpose:rag-demo]\n",
      "   Chunking Config Saved: 256 chars with 25 overlap\n",
      "   \ud83d\udca1 This chunking config will be reused for all memory creation!\n"
     ]
    }
   ],
   "source": [
    "// Create a space for our RAG demo\n",
    "const SPACE_NAME = \"RAG Demo Knowledge Base (Go)\"\n",
    "\n",
    "// Define chunking configuration that we'll reuse throughout the tutorial\n",
    "func get_chunking_config() *goodmem_client.ChunkingConfiguration {\n",
    "    jsonData := `\n",
    "    {\n",
    "        \"recursive\": {\n",
    "            \"chunkSize\":           256,\n",
    "            \"chunkOverlap\":        25,\n",
    "            \"separators\":          [\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            \"keepStrategy\":        \"KEEP_END\",\n",
    "            \"separatorIsRegex\":    false,\n",
    "            \"lengthMeasurement\":   \"CHARACTER_COUNT\"\n",
    "        }\n",
    "    }`\n",
    "\n",
    "    var config goodmem_client.NullableChunkingConfiguration\n",
    "    json.Unmarshal([]byte(jsonData), &config)\n",
    "    return config.Get()\n",
    "}\n",
    "var DEMO_CHUNKING_CONFIG = get_chunking_config()\n",
    "\n",
    "func create_demo_space() string {\n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    // Check if space already exists\n",
    "    existingSpaces, _, _ := client.SpacesAPI.ListSpaces(ctx).Execute()\n",
    "    var demoSpace *goodmem_client.Space\n",
    "    \n",
    "    for _, space := range existingSpaces.Spaces {\n",
    "        if space.Name == SPACE_NAME {\n",
    "            fmt.Printf(\"\ud83d\udcc1 Space '%s' already exists\\n\", SPACE_NAME)\n",
    "            fmt.Printf(\"   Space ID: %s\\n\", space.SpaceId)\n",
    "            fmt.Println(\"   To remove existing space, see https://docs.goodmem.ai/docs/reference/cli/goodmem_space_delete/\")\n",
    "            demoSpace = &space\n",
    "            return demoSpace.SpaceId\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if demoSpace == nil {\n",
    "        // Configure space embedders if we have available embedders\n",
    "        defaultEmbedder := getEmbedders()[0]\n",
    "        var spaceEmbedders []goodmem_client.SpaceEmbedderConfig\n",
    "        spaceEmbedders = []goodmem_client.SpaceEmbedderConfig{\n",
    "            {\n",
    "                EmbedderId:              defaultEmbedder.EmbedderId,\n",
    "                DefaultRetrievalWeight:  1.0,\n",
    "            },\n",
    "        }\n",
    "    \n",
    "        falseValue := false\n",
    "        falseBool := goodmem_client.NewNullableBool(&falseValue)\n",
    "        // Create space request\n",
    "        createRequest := goodmem_client.SpaceCreationRequest{\n",
    "            Name: SPACE_NAME,\n",
    "            Labels: map[string]string{\n",
    "                \"purpose\":      \"rag-demo\",\n",
    "                \"environment\":  \"tutorial\",\n",
    "                \"content-type\": \"documentation\",\n",
    "            },\n",
    "            SpaceEmbedders:          spaceEmbedders,\n",
    "            PublicRead:              *falseBool,\n",
    "            DefaultChunkingConfig:   DEMO_CHUNKING_CONFIG,\n",
    "        }\n",
    "        \n",
    "        // Create the space\n",
    "        newSpace, httpResp, err := client.SpacesAPI.CreateSpace(ctx).SpaceCreationRequest(createRequest).Execute()\n",
    "        if err != nil {\n",
    "            log.Fatalf(\"\u274c Error creating space: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "        }\n",
    "        \n",
    "        demoSpace = newSpace\n",
    "        \n",
    "        fmt.Printf(\"\u2705 Created space: %s\\n\", newSpace.Name)\n",
    "        fmt.Printf(\"   Space ID: %s\\n\", newSpace.SpaceId)\n",
    "        fmt.Printf(\"   Embedders: %d\\n\", len(newSpace.SpaceEmbedders))\n",
    "        if newSpace.Labels != nil {\n",
    "            fmt.Printf(\"   Labels: %v\\n\", newSpace.Labels)\n",
    "        }\n",
    "        fmt.Println(\"   Chunking Config Saved: 256 chars with 25 overlap\")\n",
    "        fmt.Println(\"   \ud83d\udca1 This chunking config will be reused for all memory creation!\")\n",
    "        return demoSpace.SpaceId\n",
    "    }\n",
    "    return \"\"\n",
    "}\n",
    "\n",
    "var demoSpaceId = cache.Cache(\"demoSpaceId\", create_demo_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "get-space",
    "description": "Verify space configuration",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d Space Configuration:\n",
      "   Name: RAG Demo Knowledge Base (Go)\n",
      "   Owner ID: cf5df949-31c6-4c54-af50-f8002107164e\n",
      "   Public Read: false\n",
      "   Created: 1765502292472\n",
      "   Labels: map[content-type:documentation environment:tutorial purpose:rag-demo]\n",
      "\n",
      "\ud83e\udd16 Associated Embedders:\n",
      "   Embedder ID: 258ede3c-af3a-4e8e-87e1-87f5ff9a64be\n",
      "   Retrieval Weight: 1.0\n"
     ]
    }
   ],
   "source": [
    "// Verify our space configuration\n",
    "%%\n",
    "if demoSpaceId != \"\" {\n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    \n",
    "    spaceDetails, httpResp, err := client.SpacesAPI.GetSpace(ctx, demoSpaceId).Execute()\n",
    "    if err != nil {\n",
    "        log.Fatalf(\"\u274c Error getting space details: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "    }\n",
    "    \n",
    "    fmt.Println(\"\ud83d\udd0d Space Configuration:\")\n",
    "    fmt.Printf(\"   Name: %s\\n\", spaceDetails.Name)\n",
    "    fmt.Printf(\"   Owner ID: %s\\n\", spaceDetails.OwnerId)\n",
    "    fmt.Printf(\"   Public Read: %v\\n\", spaceDetails.PublicRead)\n",
    "    fmt.Printf(\"   Created: %d\\n\", spaceDetails.CreatedAt)\n",
    "    if spaceDetails.Labels != nil {\n",
    "        fmt.Printf(\"   Labels: %v\\n\", spaceDetails.Labels)\n",
    "    }\n",
    "    \n",
    "    fmt.Println(\"\\n\ud83e\udd16 Associated Embedders:\")\n",
    "    for _, embedderAssoc := range spaceDetails.SpaceEmbedders {\n",
    "        fmt.Printf(\"   Embedder ID: %s\\n\", embedderAssoc.EmbedderId)\n",
    "        fmt.Printf(\"   Retrieval Weight: %.1f\\n\", embedderAssoc.DefaultRetrievalWeight)\n",
    "    }\n",
    "} else {\n",
    "    fmt.Println(\"\u26a0\ufe0f  No space available for the demo\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "documents-header",
    "description": "Document processing pipeline explanation",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Adding Documents to Memory\n",
    "\n",
    "### The Document Processing Pipeline\n",
    "\n",
    "When you add a document to GoodMem, it goes through several automated steps:\n",
    "\n",
    "```\n",
    "1. Ingestion \u2192 2. Chunking \u2192 3. Embedding \u2192 4. Indexing \u2192 5. Ready for Search\n",
    "```\n",
    "\n",
    "**What happens**:\n",
    "1. **Ingestion**: Document content and metadata are stored\n",
    "2. **Chunking**: Text is split according to your configuration (256 chars, 25 overlap)\n",
    "3. **Embedding**: Each chunk is converted to a vector by your embedder\n",
    "4. **Indexing**: Vectors are indexed for fast similarity search\n",
    "5. **Status**: Document marked as `COMPLETED` and ready for retrieval\n",
    "\n",
    "### Single vs. Batch Operations\n",
    "\n",
    "**Single memory creation** (`CreateMemory`):\n",
    "- \u2705 Good for: Real-time ingestion, single documents\n",
    "- \u2705 Synchronous processing with immediate status\n",
    "- \u26a0\ufe0f Higher overhead for bulk operations\n",
    "\n",
    "**Batch memory creation** (`BatchCreateMemory`):\n",
    "- \u2705 Good for: Bulk imports, initial setup, periodic updates\n",
    "- \u2705 Lower overhead, efficient for multiple documents\n",
    "- \u2705 Async processing - check status via `ListMemories`\n",
    "- \u26a0\ufe0f Takes longer to get individual status feedback\n",
    "\n",
    "### Metadata Best Practices\n",
    "\n",
    "Rich metadata helps with:\n",
    "- **Filtering**: Retrieve specific document types\n",
    "- **Source attribution**: Show users where information came from\n",
    "- **Organization**: Group and manage related documents\n",
    "- **Debugging**: Track ingestion methods and dates\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Load sample documents from local files\n",
    "2. Create one document using single memory creation (to demo the API)\n",
    "3. Create remaining documents using batch operation (more efficient)\n",
    "4. Monitor processing status until all documents are ready\n",
    "\n",
    "We'll use sample company documents that represent common business use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "cache-reset-sample-docs",
    "description": "Reset gonb cache for sampleDocs variable",
    "notebook": "go"
   },
   "outputs": [],
   "source": [
    "// Execute to clear gonb cache on memoryId\n",
    "%%\n",
    "cache.ResetKey(\"sampleDocs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "load-documents",
    "description": "Load sample documents from files",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcc4 Loaded: company_handbook.txt (2342 characters)\n",
      "\ud83d\udcc4 Loaded: employee_handbook.pdf (399615 bytes, base64: 532820 chars)\n",
      "\ud83d\udcc4 Loaded: product_faq.txt (4043 characters)\n",
      "\ud83d\udcc4 Loaded: security_policy.txt (4211 characters)\n",
      "\ud83d\udcc4 Loaded: technical_documentation.txt (2384 characters)\n",
      "\n",
      "\ud83d\udcda Total documents loaded: 5\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"io/ioutil\"\n",
    "    \"path/filepath\"\n",
    "    \"encoding/base64\"\n",
    "    \"sort\"\n",
    ")\n",
    "\n",
    "// Document structure\n",
    "type Document struct {\n",
    "    Filename    string\n",
    "    Content     string\n",
    "    ContentB64  string\n",
    "    ContentType string\n",
    "    IsBinary    bool\n",
    "}\n",
    "\n",
    "// Load sample documents with auto-discovery\n",
    "func loadSampleDocuments() []Document {\n",
    "    /**\n",
    "     * Load sample documents from the sample_documents directory.\n",
    "     * \n",
    "     * Automatically discovers all files in the directory and handles:\n",
    "     * - .txt files: Read as plain text\n",
    "     * - .pdf files: Read as binary and base64 encode\n",
    "     */\n",
    "    documents := []Document{}\n",
    "    sampleDir := \"sample_documents\"\n",
    "    \n",
    "    // Check if directory exists and read files\n",
    "    files, err := ioutil.ReadDir(sampleDir)\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"\u26a0\ufe0f  Directory not found: %s\\n\", sampleDir)\n",
    "        return documents\n",
    "    }\n",
    "    \n",
    "    // Sort files for consistent ordering\n",
    "    sort.Slice(files, func(i, j int) bool {\n",
    "        return files[i].Name() < files[j].Name()\n",
    "    })\n",
    "    \n",
    "    for _, fileInfo := range files {\n",
    "        if fileInfo.IsDir() {\n",
    "            continue\n",
    "        }\n",
    "        \n",
    "        filename := fileInfo.Name()\n",
    "        fullPath := filepath.Join(sampleDir, filename)\n",
    "        ext := filepath.Ext(filename)\n",
    "        \n",
    "        if ext == \".txt\" {\n",
    "            // Handle text files\n",
    "            content, err := ioutil.ReadFile(fullPath)\n",
    "            if err != nil {\n",
    "                fmt.Printf(\"\u26a0\ufe0f  Error reading %s: %v\\n\", filename, err)\n",
    "                continue\n",
    "            }\n",
    "            \n",
    "            documents = append(documents, Document{\n",
    "                Filename:    filename,\n",
    "                Content:     string(content),\n",
    "                ContentType: \"text/plain\",\n",
    "                IsBinary:    false,\n",
    "            })\n",
    "            \n",
    "            fmt.Printf(\"\ud83d\udcc4 Loaded: %s (%d characters)\\n\", filename, len(content))\n",
    "            \n",
    "        } else if ext == \".pdf\" {\n",
    "            // Handle PDF files with base64 encoding\n",
    "            binaryContent, err := ioutil.ReadFile(fullPath)\n",
    "            if err != nil {\n",
    "                fmt.Printf(\"\u26a0\ufe0f  Error reading %s: %v\\n\", filename, err)\n",
    "                continue\n",
    "            }\n",
    "            \n",
    "            contentB64 := base64.StdEncoding.EncodeToString(binaryContent)\n",
    "            \n",
    "            documents = append(documents, Document{\n",
    "                Filename:    filename,\n",
    "                ContentB64:  contentB64,\n",
    "                ContentType: \"application/pdf\",\n",
    "                IsBinary:    true,\n",
    "            })\n",
    "            \n",
    "            fmt.Printf(\"\ud83d\udcc4 Loaded: %s (%d bytes, base64: %d chars)\\n\", filename, len(binaryContent), len(contentB64))\n",
    "            \n",
    "        } else {\n",
    "            fmt.Printf(\"\u26a0\ufe0f  Skipping unsupported file type: %s\\n\", filename)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return documents\n",
    "}\n",
    "\n",
    "// Load the documents\n",
    "var sampleDocs = cache.Cache(\"sampleDocs\", loadSampleDocuments)\n",
    "\n",
    "%%\n",
    "fmt.Printf(\"\\n\ud83d\udcda Total documents loaded: %d\\n\", len(sampleDocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "cache-reset-memory",
    "description": "Reset gonb cache for memoryId variable",
    "notebook": "go"
   },
   "outputs": [],
   "source": [
    "// Execute to clear gonb cache on memoryId\n",
    "%%\n",
    "cache.ResetKey(\"memoryId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "create-single-memory",
    "description": "Create first memory individually",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Creating first document using CreateMemory API:\n",
      "   Document: company_handbook.txt\n",
      "   Content Type: text/plain\n",
      "   Method: Individual memory creation\n",
      "\n",
      "\u2705 Created single memory: company_handbook.txt\n",
      "   Memory ID: c0a0b6fb-73c2-4a77-9c66-968dca22ce59\n",
      "   Content Type: text/plain\n",
      "   Status: PENDING\n",
      "\n",
      "\ud83c\udfaf Single memory creation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import \"strings\"\n",
    "\n",
    "// Create the first memory individually to demonstrate single memory creation\n",
    "func createMemory() string {\n",
    "    createSingleMemory := func(spaceId string, document Document) (*goodmem_client.Memory, error) {\n",
    "        // Create memory request - use appropriate content field based on binary flag\n",
    "        memoryRequest := goodmem_client.MemoryCreationRequest{\n",
    "            SpaceId:        spaceId,\n",
    "            ContentType:    document.ContentType,\n",
    "            ChunkingConfig: DEMO_CHUNKING_CONFIG,\n",
    "            Metadata: map[string]interface{}{\n",
    "                \"filename\":         document.Filename,\n",
    "                \"source\":           \"sample_documents\",\n",
    "                \"ingestion_method\": \"single\",\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        // Add content field based on type\n",
    "        if document.IsBinary {\n",
    "            memoryRequest.OriginalContentB64 = *goodmem_client.NewNullableString(&document.ContentB64)\n",
    "        } else {\n",
    "            memoryRequest.OriginalContent = *goodmem_client.NewNullableString(&document.Content)\n",
    "        }\n",
    "        \n",
    "        // Create the memory\n",
    "        client := getClient()\n",
    "        ctx := context.Background()\n",
    "        memory, httpResp, err := client.MemoriesAPI.CreateMemory(ctx).MemoryCreationRequest(memoryRequest).Execute()\n",
    "        if err != nil {\n",
    "            return nil, fmt.Errorf(\"failed to create memory: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "        }\n",
    "        \n",
    "        fmt.Printf(\"\u2705 Created single memory: %s\\n\", document.Filename)\n",
    "        fmt.Printf(\"   Memory ID: %s\\n\", memory.MemoryId)\n",
    "        fmt.Printf(\"   Content Type: %s\\n\", document.ContentType)\n",
    "        fmt.Printf(\"   Status: %s\\n\", memory.ProcessingStatus)\n",
    "        fmt.Println()\n",
    "        \n",
    "        return memory, nil\n",
    "    }\n",
    "    \n",
    "    var singleMemory *goodmem_client.Memory\n",
    "    \n",
    "    if len(sampleDocs) > 0 {\n",
    "        firstDoc := sampleDocs[0]\n",
    "        fmt.Println(\"\ud83d\udcdd Creating first document using CreateMemory API:\")\n",
    "        fmt.Printf(\"   Document: %s\\n\", firstDoc.Filename)\n",
    "        fmt.Printf(\"   Content Type: %s\\n\", firstDoc.ContentType)\n",
    "        fmt.Println(\"   Method: Individual memory creation\")\n",
    "        fmt.Println()\n",
    "        \n",
    "        memory, err := createSingleMemory(demoSpaceId, firstDoc)\n",
    "        if err != nil {\n",
    "            fmt.Printf(\"\u26a0\ufe0f  Single memory creation failed: %v\\n\", err)\n",
    "        } else {\n",
    "            singleMemory = memory\n",
    "            fmt.Println(\"\ud83c\udfaf Single memory creation completed successfully!\")\n",
    "        }\n",
    "    } else {\n",
    "        fmt.Println(\"\u26a0\ufe0f  Cannot create memory: missing space or documents\")\n",
    "    }\n",
    "    return singleMemory.MemoryId\n",
    "}\n",
    "\n",
    "var memoryId = cache.Cache(\"memoryId\", createMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "get-memory-with-content",
    "description": "Retrieve memory by ID with content",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcd6 Retrieving memory details using GetMemory API:\n",
      "   Memory ID: c0a0b6fb-73c2-4a77-9c66-968dca22ce59\n",
      "\n",
      "\u2705 Successfully retrieved memory:\n",
      "   Memory ID: c0a0b6fb-73c2-4a77-9c66-968dca22ce59\n",
      "   Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "   Status: PENDING\n",
      "   Content Type: text/plain\n",
      "   Created At: 1765502298161\n",
      "   Updated At: 1765502298161\n",
      "\n",
      "   \ud83d\udccb Metadata:\n",
      "      source: sample_documents\n",
      "      filename: company_handbook.txt\n",
      "      ingestion_method: single\n",
      "\n",
      "\ud83d\udcd6 Retrieving memory with content:\n",
      "\u2705 Content retrieved and decoded:\n",
      "   Content length: 2342 characters\n",
      "   First 200 chars: ACME Corporation Employee Handbook\n",
      "\n",
      "Welcome to ACME Corporation! This handbook provides essential information about our company policies, procedures, and culture.\n",
      "\n",
      "COMPANY OVERVIEW\n",
      "ACME Corporation is...\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "// Demonstrate retrieving a memory by ID using get_memory\n",
    "fmt.Println(\"\ud83d\udcd6 Retrieving memory details using GetMemory API:\")\n",
    "fmt.Printf(\"   Memory ID: %s\\n\", memoryId)\n",
    "fmt.Println()\n",
    "\n",
    "client := getClient()\n",
    "ctx := context.Background()\n",
    "// Retrieve the memory without content\n",
    "retrievedMemory, httpResp, err := client.MemoriesAPI.GetMemory(ctx, memoryId).IncludeContent(false).Execute()\n",
    "if err != nil {\n",
    "    log.Fatalf(\"\u274c Error retrieving memory: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "}\n",
    "\n",
    "fmt.Println(\"\u2705 Successfully retrieved memory:\")\n",
    "fmt.Printf(\"   Memory ID: %s\\n\", retrievedMemory.MemoryId)\n",
    "fmt.Printf(\"   Space ID: %s\\n\", retrievedMemory.SpaceId)\n",
    "fmt.Printf(\"   Status: %s\\n\", retrievedMemory.ProcessingStatus)\n",
    "fmt.Printf(\"   Content Type: %s\\n\", retrievedMemory.ContentType)\n",
    "fmt.Printf(\"   Created At: %d\\n\", retrievedMemory.CreatedAt)\n",
    "fmt.Printf(\"   Updated At: %d\\n\", retrievedMemory.UpdatedAt)\n",
    "\n",
    "if retrievedMemory.Metadata != nil {\n",
    "    fmt.Println(\"\\n   \ud83d\udccb Metadata:\")\n",
    "    for key, value := range retrievedMemory.Metadata {\n",
    "        fmt.Printf(\"      %s: %v\\n\", key, value)\n",
    "    }\n",
    "}\n",
    "\n",
    "// Now retrieve with content included\n",
    "fmt.Println(\"\\n\ud83d\udcd6 Retrieving memory with content:\")\n",
    "retrievedWithContent, httpResp, err := client.MemoriesAPI.GetMemory(ctx, memoryId).IncludeContent(true).Execute()\n",
    "if err != nil {\n",
    "    log.Fatalf(\"\u274c Error retrieving memory with content: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "}\n",
    "\n",
    "if retrievedWithContent.OriginalContent.IsSet() {\n",
    "    // Decode the base64 encoded content\n",
    "    decodedContent, err := base64.StdEncoding.DecodeString(*retrievedWithContent.OriginalContent.Get())\n",
    "    if err != nil {\n",
    "        log.Fatalf(\"\u274c Error decoding content: %v\", err)\n",
    "    }\n",
    "    \n",
    "    contentStr := string(decodedContent)\n",
    "    fmt.Println(\"\u2705 Content retrieved and decoded:\")\n",
    "    fmt.Printf(\"   Content length: %d characters\\n\", len(contentStr))\n",
    "    if len(contentStr) > 200 {\n",
    "        fmt.Printf(\"   First 200 chars: %s...\\n\", contentStr[:200])\n",
    "    } else {\n",
    "        fmt.Printf(\"   Content: %s\\n\", contentStr)\n",
    "    }\n",
    "} else {\n",
    "    fmt.Println(\"\u26a0\ufe0f  No content available\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "batch-create-memories",
    "description": "Batch create remaining memories",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udce6 Creating 4 memories using BatchCreateMemory API:\n",
      "\n",
      "\ud83d\udccb Total Memory Creation Summary:\n",
      "   \ud83d\udcc4 Single CreateMemory: 1 document\n",
      "   \ud83d\udce6 Batch CreateMemory: 4 documents submitted\n",
      "   \u23f3 Check processing status in the next cell\n"
     ]
    }
   ],
   "source": [
    "// Create the remaining documents using batch memory creation\n",
    "func createBatchMemories(spaceId string, documents []Document) error {\n",
    "    var memoryRequests []goodmem_client.MemoryCreationRequest\n",
    "    \n",
    "    for _, doc := range documents {\n",
    "        memoryRequest := goodmem_client.MemoryCreationRequest{\n",
    "            SpaceId:        spaceId,\n",
    "            ContentType:    doc.ContentType,\n",
    "            ChunkingConfig: DEMO_CHUNKING_CONFIG,\n",
    "            Metadata: map[string]interface{}{\n",
    "                \"filename\":         doc.Filename,\n",
    "                \"source\":           \"sample_documents\",\n",
    "                \"ingestion_method\": \"batch\",\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        // Add content field based on type\n",
    "        if doc.IsBinary {\n",
    "            memoryRequest.OriginalContentB64 = *goodmem_client.NewNullableString(&doc.ContentB64)\n",
    "        } else {\n",
    "            memoryRequest.OriginalContent = *goodmem_client.NewNullableString(&doc.Content)\n",
    "        }\n",
    "        \n",
    "        memoryRequests = append(memoryRequests, memoryRequest)\n",
    "    }\n",
    "    \n",
    "    // Create batch request\n",
    "    batchRequest := goodmem_client.BatchMemoryCreationRequest{\n",
    "        Requests: memoryRequests,\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"\ud83d\udce6 Creating %d memories using BatchCreateMemory API:\\n\", len(memoryRequests))\n",
    "\n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    // Execute batch creation\n",
    "    httpResp, err := client.MemoriesAPI.BatchCreateMemory(ctx).BatchMemoryCreationRequest(batchRequest).Execute()\n",
    "    if err != nil {\n",
    "        return fmt.Errorf(\"batch creation failed: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "    }\n",
    "    \n",
    "    return nil\n",
    "}\n",
    "\n",
    "%%\n",
    "if len(sampleDocs) > 1 {\n",
    "    // Create the remaining documents (skip the first one we already created)\n",
    "    remainingDocs := sampleDocs[1:]\n",
    "    err := createBatchMemories(demoSpaceId, remainingDocs)\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"\u26a0\ufe0f  Batch creation error: %v\\n\", err)\n",
    "    }\n",
    "    \n",
    "    fmt.Println(\"\\n\ud83d\udccb Total Memory Creation Summary:\")\n",
    "    fmt.Println(\"   \ud83d\udcc4 Single CreateMemory: 1 document\")\n",
    "    fmt.Printf(\"   \ud83d\udce6 Batch CreateMemory: %d documents submitted\\n\", len(remainingDocs))\n",
    "    fmt.Println(\"   \u23f3 Check processing status in the next cell\")\n",
    "} else {\n",
    "    fmt.Println(\"\u26a0\ufe0f  Cannot create batch memories: insufficient documents or missing space\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "list-memories",
    "description": "List all memories in space",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcda Memories in space '50a96fe3-280e-4efe-a4af-adb9103dc827':\n",
      "   Total memories: 5\n",
      "\n",
      "   1. security_policy.txt\n",
      "      Status: PENDING\n",
      "      Created: 1765502300413\n",
      "      Metadata:\n",
      "         ingestion_method: batch\n",
      "         source: sample_documents\n",
      "         filename: security_policy.txt\n",
      "\n",
      "   2. product_faq.txt\n",
      "      Status: PENDING\n",
      "      Created: 1765502300413\n",
      "      Metadata:\n",
      "         filename: product_faq.txt\n",
      "         ingestion_method: batch\n",
      "         source: sample_documents\n",
      "\n",
      "   3. technical_documentation.txt\n",
      "      Status: PENDING\n",
      "      Created: 1765502300413\n",
      "      Metadata:\n",
      "         source: sample_documents\n",
      "         filename: technical_documentation.txt\n",
      "         ingestion_method: batch\n",
      "\n",
      "   4. employee_handbook.pdf\n",
      "      Status: PENDING\n",
      "      Created: 1765502300413\n",
      "      Metadata:\n",
      "         source: sample_documents\n",
      "         filename: employee_handbook.pdf\n",
      "         ingestion_method: batch\n",
      "\n",
      "   5. company_handbook.txt\n",
      "      Status: PENDING\n",
      "      Created: 1765502298161\n",
      "      Metadata:\n",
      "         source: sample_documents\n",
      "         filename: company_handbook.txt\n",
      "         ingestion_method: single\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// List all memories in our space to verify they're ready\n",
    "%%\n",
    "client := getClient()\n",
    "ctx := context.Background()\n",
    "memoriesResponse, httpResp, err := client.MemoriesAPI.ListMemories(ctx, demoSpaceId).Execute()\n",
    "if err != nil {\n",
    "    log.Fatalf(\"\u274c Failed to list memories: %v (HTTP Status: %d)\", err, httpResp.StatusCode)\n",
    "}\n",
    "\n",
    "memories := memoriesResponse.Memories\n",
    "\n",
    "fmt.Printf(\"\ud83d\udcda Memories in space '%s':\\n\", demoSpaceId)\n",
    "fmt.Printf(\"   Total memories: %d\\n\", len(memories))\n",
    "fmt.Println()\n",
    "\n",
    "for i, memory := range memories {\n",
    "    var filename string\n",
    "    if memory.Metadata != nil {\n",
    "        if fn, ok := (memory.Metadata)[\"filename\"]; ok {\n",
    "            filename = fmt.Sprintf(\"%v\", fn)\n",
    "        } else {\n",
    "            filename = \"Unknown\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"   %d. %s\\n\", i+1, filename)\n",
    "    fmt.Printf(\"      Status: %s\\n\", memory.ProcessingStatus)\n",
    "    fmt.Printf(\"      Created: %d\\n\", memory.CreatedAt)\n",
    "    \n",
    "    if memory.Metadata != nil {\n",
    "        fmt.Println(\"      Metadata:\")\n",
    "        for key, value := range memory.Metadata {\n",
    "            fmt.Printf(\"         %s: %v\\n\", key, value)\n",
    "        }\n",
    "    }\n",
    "    fmt.Println()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "monitor-processing",
    "description": "Monitor document processing status",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u23f3 Waiting for document processing to complete...\n",
      "   \ud83d\udca1 Note: Batch memories are processed asynchronously, so we check by listing all memories in the space\n",
      "\n",
      "\ud83d\udcca Processing status: map[COMPLETED:4 PENDING:1] (Total: 5 memories)\n",
      "\ud83d\udcca Processing status: map[COMPLETED:5] (Total: 5 memories)\n",
      "\u2705 All documents processed successfully!\n",
      "\ud83c\udf89 Ready for semantic search and retrieval!\n",
      "\ud83d\udcc8 Batch API benefit: Multiple documents submitted in a single API call\n",
      "\ud83d\udd27 Consistent chunking: All memories use DEMO_CHUNKING_CONFIG\n"
     ]
    }
   ],
   "source": [
    "// Monitor processing status for all created memories\n",
    "func waitForProcessingCompletion(spaceId string, maxWaitSeconds int) bool {\n",
    "    fmt.Println(\"\u23f3 Waiting for document processing to complete...\")\n",
    "    fmt.Println(\"   \ud83d\udca1 Note: Batch memories are processed asynchronously, so we check by listing all memories in the space\")\n",
    "    fmt.Println()\n",
    "    \n",
    "    startTime := time.Now()\n",
    "    maxWaitDuration := time.Duration(maxWaitSeconds) * time.Second\n",
    "\n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    for time.Since(startTime) < maxWaitDuration {\n",
    "        memoriesResponse, httpResp, err := client.MemoriesAPI.ListMemories(ctx, spaceId).Execute()\n",
    "        if err != nil {\n",
    "            fmt.Printf(\"\u274c Error checking processing status: %v (HTTP Status: %d)\\n\", err, httpResp.StatusCode)\n",
    "            return false\n",
    "        }\n",
    "        \n",
    "        memories := memoriesResponse.Memories\n",
    "        \n",
    "        // Check processing status\n",
    "        statusCounts := make(map[string]int)\n",
    "        for _, memory := range memories {\n",
    "            statusCounts[memory.ProcessingStatus]++\n",
    "        }\n",
    "        \n",
    "        fmt.Printf(\"\ud83d\udcca Processing status: %v (Total: %d memories)\\n\", statusCounts, len(memories))\n",
    "        \n",
    "        // Check if all are completed\n",
    "        allCompleted := true\n",
    "        for _, memory := range memories {\n",
    "            if memory.ProcessingStatus != \"COMPLETED\" {\n",
    "                allCompleted = false\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if allCompleted {\n",
    "            fmt.Println(\"\u2705 All documents processed successfully!\")\n",
    "            return true\n",
    "        }\n",
    "        \n",
    "        // Check for failures\n",
    "        if failedCount, ok := statusCounts[\"FAILED\"]; ok && failedCount > 0 {\n",
    "            fmt.Printf(\"\u274c %d memories failed processing\\n\", failedCount)\n",
    "            return false\n",
    "        }\n",
    "        \n",
    "        time.Sleep(5 * time.Second)\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"\u23f0 Timeout waiting for processing (waited %ds)\\n\", maxWaitSeconds)\n",
    "    return false\n",
    "}\n",
    "\n",
    "%%\n",
    "processingComplete := waitForProcessingCompletion(demoSpaceId, 120)\n",
    "\n",
    "if processingComplete {\n",
    "    fmt.Println(\"\ud83c\udf89 Ready for semantic search and retrieval!\")\n",
    "    fmt.Println(\"\ud83d\udcc8 Batch API benefit: Multiple documents submitted in a single API call\")\n",
    "    fmt.Println(\"\ud83d\udd27 Consistent chunking: All memories use DEMO_CHUNKING_CONFIG\")\n",
    "} else {\n",
    "    fmt.Println(\"\u26a0\ufe0f  Some documents may still be processing. You can continue with the tutorial.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "search-header",
    "description": "Semantic search concepts and explanation",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Semantic Search & Retrieval\n",
    "\n",
    "### Why Semantic Search?\n",
    "\n",
    "**Traditional keyword search**:\n",
    "- Matches exact words or simple variations\n",
    "- Misses conceptually similar content with different wording\n",
    "- Example: \"vacation days\" won't match \"time off policy\"\n",
    "\n",
    "**Semantic search**:\n",
    "- Understands meaning and context\n",
    "- Finds conceptually similar content regardless of exact wording\n",
    "- Example: \"vacation days\" successfully matches \"time off policy\"\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Query: \"vacation policy\" \n",
    "   \u2193 (embed with same embedder)\n",
    "Query Vector: [0.23, -0.45, ...]\n",
    "   \u2193 (compare to all chunk vectors)\n",
    "Most Similar Chunks: (by cosine similarity)\n",
    "   1. \"TIME OFF POLICY...\" (score: -0.604)\n",
    "   2. \"Vacation requests...\" (score: -0.544)\n",
    "   3. \"WORK HOURS...\" (score: -0.458)\n",
    "```\n",
    "\n",
    "### Understanding Relevance Scores\n",
    "\n",
    "GoodMem uses **cosine distance** (negative cosine similarity):\n",
    "- **Lower values = more relevant** (e.g., -0.6 is better than -0.4)\n",
    "- **Range**: Typically -1.0 (most similar) to 0.0 (unrelated)\n",
    "- **Good threshold**: Results under -0.3 are usually relevant\n",
    "- **Context matters**: Exact scores vary by embedder and content\n",
    "\n",
    "### Streaming API Benefits\n",
    "\n",
    "GoodMem's streaming API:\n",
    "- **Real-time results**: Process chunks as they arrive\n",
    "- **Low latency**: Start showing results immediately\n",
    "- **Memory efficient**: No need to buffer entire result set\n",
    "- **Progressive UI**: Update interface as more results come in\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Implement a semantic search function using GoodMem's streaming API\n",
    "2. Process different event types (chunks, memories, metadata)\n",
    "3. Display results with relevance scores\n",
    "4. Test with various queries to see semantic matching in action\n",
    "\n",
    "Now comes the exciting part! Let's perform semantic search using GoodMem's streaming API. This will:\n",
    "\n",
    "- **Find relevant chunks** based on semantic similarity\n",
    "- **Stream results** in real-time\n",
    "- **Include relevance scores** for ranking\n",
    "- **Return structured data** for easy processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "semantic-search",
    "description": "Perform streaming semantic search",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d Searching for: 'What is the vacation policy for employees?'\n",
      "\ud83d\udcc1 Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "\ud83d\udcca Max results: 5\n",
      "--------------------------------------------------\n",
      "\ud83d\udcc4 Chunk 1:\n",
      "   Relevance: -0.680\n",
      "   Text: TIME OFF POLICY\n",
      "All full-time employees receive:\n",
      "- 15 days of paid vacation annually (increases to 20 days after 3 years)\n",
      "- 10 sick days per year\n",
      "- 8 company holidays\n",
      "- Personal days as needed with ma...\n",
      "\n",
      "\ud83d\udcc4 Chunk 2:\n",
      "   Relevance: -0.675\n",
      "   Text: 1.  Eligibility \n",
      "\n",
      " \n",
      "All regular full-time employees are eligible for vacation benefits. \n",
      "\n",
      " \n",
      "2.  Accrual \n",
      "\n",
      " \n",
      "Eligible employees accrue vacation in accordance with the following scheduleix: \n",
      "\n",
      " \n",
      "Years of...\n",
      "\n",
      "\ud83d\udcc4 Chunk 3:\n",
      "   Relevance: -0.662\n",
      "   Text: [ORGANIZATION] has established the following vacation plan to provide eligible employees \n",
      "time off with pay so that they may be free from their regular duties for a period of rest and \n",
      "relaxation with...\n",
      "\n",
      "\ud83d\udcc4 Chunk 4:\n",
      "   Relevance: -0.646\n",
      "   Text: Vacation Pay: Vacation pay shall be based on the employee\u2019s regular base rate and \n",
      "working schedule, exclusive of overtime.  No employee will receive pay in lieu of \n",
      "vacation, except on termination ...\n",
      "\n",
      "\ud83d\udcc4 Chunk 5:\n",
      "   Relevance: -0.643\n",
      "   Text: employees can use paid vacation time in minimum increments of one day.xii \n",
      "\n",
      " \n",
      "Accumulating Vacation: Employees are encouraged to use available paid vacation time \n",
      "for rest and relaxation.  In the even...\n",
      "\n",
      "\u2705 Search completed: 5 chunks found, 10 events processed\n"
     ]
    }
   ],
   "source": [
    "// ChunkResult represents a search result chunk\n",
    "type ChunkResult struct {\n",
    "    ChunkText      string\n",
    "    RelevanceScore float64\n",
    "    MemoryIndex    int32\n",
    "    ResultSetID    string\n",
    "    ChunkSequence  int32\n",
    "}\n",
    "\n",
    "// Perform semantic search using GoodMem's streaming API\n",
    "func semanticSearch(query string, spaceId string, maxResults int32) []ChunkResult {\n",
    "    fmt.Printf(\"\ud83d\udd0d Searching for: '%s'\\n\", query)\n",
    "    fmt.Printf(\"\ud83d\udcc1 Space ID: %s\\n\", spaceId)\n",
    "    fmt.Printf(\"\ud83d\udcca Max results: %d\\n\", maxResults)\n",
    "    fmt.Println(strings.Repeat(\"-\", 50))\n",
    "\n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    // Create streaming client\n",
    "    streamingClient := goodmem_client.NewStreamingClient(client)\n",
    "    \n",
    "    // Create stream request\n",
    "    streamReq := &goodmem_client.MemoryStreamRequest{\n",
    "        Message:            query,\n",
    "        SpaceIDs:           []string{spaceId},\n",
    "        RequestedSize:      PtrInt32(maxResults),\n",
    "        FetchMemory:        PtrBool(true),\n",
    "        FetchMemoryContent: PtrBool(false),\n",
    "        GenerateAbstract:   PtrBool(false),\n",
    "        Format:             goodmem_client.FormatNDJSON,\n",
    "    }\n",
    "    \n",
    "    // Perform streaming search\n",
    "    streamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)\n",
    "    defer cancel()\n",
    "    \n",
    "    stream, err := streamingClient.RetrieveMemoryStream(streamCtx, streamReq)\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"\u274c Failed to start streaming: %v\\n\", err)\n",
    "        return nil\n",
    "    }\n",
    "    \n",
    "    eventCount := 0\n",
    "    var retrievedChunks []ChunkResult\n",
    "    \n",
    "    for event := range stream {\n",
    "        eventCount++\n",
    "        \n",
    "        if event.RetrievedItem != nil && event.RetrievedItem.Chunk != nil {\n",
    "            chunkInfo := event.RetrievedItem.Chunk\n",
    "            chunkData := chunkInfo.Chunk\n",
    "            \n",
    "            var chunkText string\n",
    "            var chunkSeq int32\n",
    "            \n",
    "            if text, ok := chunkData[\"chunkText\"]; ok {\n",
    "                chunkText = fmt.Sprintf(\"%v\", text)\n",
    "            }\n",
    "            if seq, ok := chunkData[\"chunkSequenceNumber\"]; ok {\n",
    "                if seqFloat, ok := seq.(float64); ok {\n",
    "                    chunkSeq = int32(seqFloat)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            result := ChunkResult{\n",
    "                ChunkText:      chunkText,\n",
    "                RelevanceScore: chunkInfo.RelevanceScore,\n",
    "                MemoryIndex:    int32(chunkInfo.MemoryIndex),\n",
    "                ResultSetID:    chunkInfo.ResultSetId,\n",
    "                ChunkSequence:  chunkSeq,\n",
    "            }\n",
    "            retrievedChunks = append(retrievedChunks, result)\n",
    "            \n",
    "            fmt.Printf(\"\ud83d\udcc4 Chunk %d:\\n\", len(retrievedChunks))\n",
    "            fmt.Printf(\"   Relevance: %.3f\\n\", chunkInfo.RelevanceScore)\n",
    "            displayText := chunkText\n",
    "            if len(displayText) > 200 {\n",
    "                displayText = displayText[:200] + \"...\"\n",
    "            }\n",
    "            fmt.Printf(\"   Text: %s\\n\", displayText)\n",
    "            fmt.Println()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"\u2705 Search completed: %d chunks found, %d events processed\\n\", len(retrievedChunks), eventCount)\n",
    "    return retrievedChunks\n",
    "}\n",
    "\n",
    "%%\n",
    "// Test semantic search with a sample query\n",
    "sampleQuery := \"What is the vacation policy for employees?\"\n",
    "semanticSearch(sampleQuery, demoSpaceId, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "test-queries",
    "description": "Test multiple search queries",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83d\udd0d Test Query 1: How do I reset my password?\n",
      "============================================================\n",
      "\ud83d\udd0d Searching for: 'How do I reset my password?'\n",
      "\ud83d\udcc1 Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "\ud83d\udcca Max results: 3\n",
      "--------------------------------------------------\n",
      "\ud83d\udcc4 Chunk 1:\n",
      "   Relevance: -0.370\n",
      "   Text: password they use to gain access to computers or the Internet, as well as any change to \n",
      "such password.  Such notice must be made immediately. \n",
      "\n",
      " \n",
      "4. Compliance\n",
      "\n",
      "\ud83d\udcc4 Chunk 2:\n",
      "   Relevance: -0.363\n",
      "   Text: - No reuse of last 12 passwords\n",
      "- Must be changed every 90 days for privileged accounts\n",
      "- Multi-factor authentication required for all business systems\n",
      "- Password managers recommended for personal pas...\n",
      "\n",
      "\ud83d\udcc4 Chunk 3:\n",
      "   Relevance: -0.306\n",
      "   Text: Each classification level has specific handling, storage, and transmission requirements outlined in our data handling procedures.\n",
      "\n",
      "PASSWORD POLICY\n",
      "Strong passwords are essential for system security:\n",
      "-...\n",
      "\n",
      "\u2705 Search completed: 3 chunks found, 8 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\ud83d\udd0d Test Query 2: What are the security requirements for remote work?\n",
      "============================================================\n",
      "\ud83d\udd0d Searching for: 'What are the security requirements for remote work?'\n",
      "\ud83d\udcc1 Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "\ud83d\udcca Max results: 3\n",
      "--------------------------------------------------\n",
      "\ud83d\udcc4 Chunk 1:\n",
      "   Relevance: -0.710\n",
      "   Text: - Report suspicious emails or security incidents immediately\n",
      "\n",
      "REMOTE WORK SECURITY\n",
      "Remote employees must follow additional security measures:\n",
      "- Use company-approved VPN for all work connections\n",
      "- Ensu...\n",
      "\n",
      "\ud83d\udcc4 Chunk 2:\n",
      "   Relevance: -0.530\n",
      "   Text: - Keep work devices physically secure and locked when unattended\n",
      "- Use only approved cloud storage services for company data\n",
      "- Install automatic security updates on all devices\n",
      "\n",
      "INCIDENT RESPONSE\n",
      "Secu...\n",
      "\n",
      "\ud83d\udcc4 Chunk 3:\n",
      "   Relevance: -0.471\n",
      "   Text: SECURITY TRAINING\n",
      "All employees must complete:\n",
      "- Security awareness training within 30 days of hire\n",
      "- Annual security refresher training\n",
      "- Role-specific security training as required\n",
      "- Phishing simula...\n",
      "\n",
      "\u2705 Search completed: 3 chunks found, 7 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\ud83d\udd0d Test Query 3: API authentication and rate limits\n",
      "============================================================\n",
      "\ud83d\udd0d Searching for: 'API authentication and rate limits'\n",
      "\ud83d\udcc1 Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "\ud83d\udcca Max results: 3\n",
      "--------------------------------------------------\n",
      "\ud83d\udcc4 Chunk 1:\n",
      "   Relevance: -0.554\n",
      "   Text: BASE URL\n",
      "All API endpoints are accessed via:\n",
      "https://api.acme.com/v1/\n",
      "\n",
      "RATE LIMITING\n",
      "API requests are limited to:\n",
      "- 1000 requests per hour for free accounts\n",
      "- 10000 requests per hour for premium accou...\n",
      "\n",
      "\ud83d\udcc4 Chunk 2:\n",
      "   Relevance: -0.462\n",
      "   Text: - 403: Forbidden - Insufficient permissions\n",
      "- 404: Not Found - Resource does not exist\n",
      "- 429: Too Many Requests - Rate limit exceeded\n",
      "- 500: Internal Server Error\n",
      "\n",
      "\ud83d\udcc4 Chunk 3:\n",
      "   Relevance: -0.458\n",
      "   Text: AUTHENTICATION\n",
      "All API requests require authentication using API keys. Include your API key in the request header:\n",
      "\n",
      "Authorization: Bearer YOUR_API_KEY\n",
      "\n",
      "API keys can be generated from your account dash...\n",
      "\n",
      "\u2705 Search completed: 3 chunks found, 7 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\ud83d\udd0d Test Query 4: Employee benefits and health insurance\n",
      "============================================================\n",
      "\ud83d\udd0d Searching for: 'Employee benefits and health insurance'\n",
      "\ud83d\udcc1 Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "\ud83d\udcca Max results: 3\n",
      "--------------------------------------------------\n",
      "\ud83d\udcc4 Chunk 1:\n",
      "   Relevance: -0.600\n",
      "   Text: - Health insurance with 90% premium coverage\n",
      "- Dental and vision insurance\n",
      "- 401(k) retirement plan with 4% company match\n",
      "- Life insurance equal to 2x annual salary\n",
      "- Employee stock options after 1 ye...\n",
      "\n",
      "\ud83d\udcc4 Chunk 2:\n",
      "   Relevance: -0.590\n",
      "   Text: A. Employee Benefits.......................................................................................................................13\n",
      "\n",
      "\ud83d\udcc4 Chunk 3:\n",
      "   Relevance: -0.586\n",
      "   Text: [ORGANIZATION]. \n",
      "\n",
      " \n",
      "F. Health Insurance \n",
      "\n",
      " \n",
      "\n",
      "All employees classified by [ORGANIZATION] as regularly working at least 30 hours per week \n",
      "and their dependents currently are eligible to participate in [...\n",
      "\n",
      "\u2705 Search completed: 3 chunks found, 8 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\ud83d\udd0d Test Query 5: How much does the software cost?\n",
      "============================================================\n",
      "\ud83d\udd0d Searching for: 'How much does the software cost?'\n",
      "\ud83d\udcc1 Space ID: 50a96fe3-280e-4efe-a4af-adb9103dc827\n",
      "\ud83d\udcca Max results: 3\n",
      "--------------------------------------------------\n",
      "\ud83d\udcc4 Chunk 1:\n",
      "   Relevance: -0.496\n",
      "   Text: A: The ACME Software Suite is an integrated platform that provides business management tools including CRM, project management, analytics, and automation capabilities. It's designed to streamline oper...\n",
      "\n",
      "\ud83d\udcc4 Chunk 2:\n",
      "   Relevance: -0.471\n",
      "   Text: A: We offer three pricing tiers:\n",
      "- Starter: $29/month for up to 5 users\n",
      "- Professional: $79/month for up to 25 users\n",
      "- Enterprise: $199/month for unlimited users\n",
      "All plans include core features with i...\n",
      "\n",
      "\ud83d\udcc4 Chunk 3:\n",
      "   Relevance: -0.425\n",
      "   Text: Q: Is there a free trial available?\n",
      "A: Yes, we offer a 14-day free trial with full access to all Professional tier features. No credit card required to start your trial.\n",
      "\n",
      "TECHNICAL QUESTIONS\n",
      "\n",
      "\u2705 Search completed: 3 chunks found, 7 events processed\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "// Let's try a few different queries to see how semantic search works\n",
    "func testMultipleQueries(spaceId string) {\n",
    "    testQueries := []string{\n",
    "        \"How do I reset my password?\",\n",
    "        \"What are the security requirements for remote work?\",\n",
    "        \"API authentication and rate limits\",\n",
    "        \"Employee benefits and health insurance\",\n",
    "        \"How much does the software cost?\",\n",
    "    }\n",
    "    \n",
    "    for i, query := range testQueries {\n",
    "        fmt.Printf(\"\\n\ud83d\udd0d Test Query %d: %s\\n\", i+1, query)\n",
    "        fmt.Println(strings.Repeat(\"=\", 60))\n",
    "        \n",
    "        semanticSearch(query, spaceId, 3)\n",
    "        \n",
    "        fmt.Println(\"\\n\" + strings.Repeat(\"-\", 60))\n",
    "    }\n",
    "}\n",
    "\n",
    "%%\n",
    "testMultipleQueries(demoSpaceId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "advanced-header",
    "description": "Advanced features section header",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Advanced Features\n",
    "\n",
    "Congratulations! \ud83c\udf89 You've successfully built a semantic search system using GoodMem. Here's what you've accomplished:\n",
    "\n",
    "### \u2705 What You Built\n",
    "- **Document ingestion pipeline** with automatic chunking and embedding\n",
    "- **Semantic search system** with relevance scoring\n",
    "- **Simple Q&A system** using GoodMem's vector capabilities\n",
    "\n",
    "### \ud83d\ude80 Next Steps for Advanced Implementation\n",
    "\n",
    "#### Reranking\n",
    "Improve search quality by adding a reranking stage. **Rerankers** are specialized models that re-score search results to improve relevance:\n",
    "\n",
    "- **Two-stage retrieval**: Fast initial retrieval with embeddings, then precise reranking\n",
    "- **Better relevance**: Rerankers use cross-attention to understand query-document relationships\n",
    "- **Reduced costs**: Rerank only top-K results instead of entire corpus\n",
    "- **Voyage AI reranker**: Industry-leading reranking model with state-of-the-art performance\n",
    "\n",
    "The combination of fast embedding-based retrieval followed by accurate reranking provides the best balance of speed and quality for production RAG systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "reranker-header",
    "description": "Reranker explanation and concepts",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Configuring a Reranker\n",
    "\n",
    "To further improve search quality, we can add a **reranker** to our RAG pipeline. While embedders provide fast semantic search, rerankers use more sophisticated models to re-score the top results for better accuracy.\n",
    "\n",
    "### Why Use Reranking?\n",
    "\n",
    "1. **Higher Accuracy**: Rerankers use cross-encoder architectures that directly compare queries and documents\n",
    "2. **Two-Stage Pipeline**: Fast retrieval with embeddings + precise reranking = optimal performance\n",
    "3. **Cost Effective**: Only rerank top-K results (e.g., top 20) rather than entire corpus\n",
    "\n",
    "### Voyage AI Reranker\n",
    "\n",
    "We'll use Voyage AI's `rerank-2.5` model, which provides:\n",
    "- **State-of-the-art performance** on reranking benchmarks\n",
    "- **Fast inference** optimized for production use\n",
    "- **Simple API** that integrates seamlessly with GoodMem\n",
    "\n",
    "**Note**: You'll need a Voyage AI API key set in your environment variable `VOYAGE_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "cache-reset-reranker",
    "description": "Reset gonb cache for voyageRerankerId variable",
    "notebook": "go"
   },
   "outputs": [],
   "source": [
    "// Execute to clear gonb cache on voyageRerankerId\n",
    "%%\n",
    "cache.ResetKey(\"voyageRerankerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "create-reranker",
    "description": "Create Voyage AI reranker",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Creating new Voyage AI rerank-2.5 reranker...\n",
      "\u2705 Successfully created Voyage reranker\n",
      "   Display Name: Voyage Rerank 2.5\n",
      "   Reranker ID: 950de400-8c06-44c9-98d9-9d7ce953afd9\n",
      "   Model: rerank-2.5\n"
     ]
    }
   ],
   "source": [
    "// Create Voyage AI rerank-2.5 reranker\n",
    "func createVoyageReranker() string {\n",
    "    voyageApiKey := getEnv(\"VOYAGE_API_KEY\", \"\")\n",
    "    if voyageApiKey == \"\" {\n",
    "        fmt.Println(\"\u26a0\ufe0f  VOYAGE_API_KEY environment variable not set\")\n",
    "        fmt.Println(\"   Please set your Voyage AI API key to create a reranker\")\n",
    "        return \"\"\n",
    "    }\n",
    "    \n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    \n",
    "    // Check if reranker already exists\n",
    "    existingRerankers, _, _ := client.RerankersAPI.ListRerankers(ctx).Execute()\n",
    "    for _, reranker := range existingRerankers.Rerankers {\n",
    "        if reranker.ProviderType == \"VOYAGE\" && reranker.ModelIdentifier == \"rerank-2.5\" {\n",
    "            fmt.Printf(\"\u2705 Voyage reranker already exists\\n\")\n",
    "            fmt.Printf(\"   Display Name: %s\\n\", reranker.DisplayName)\n",
    "            fmt.Printf(\"   Reranker ID: %s\\n\", reranker.RerankerId)\n",
    "            fmt.Printf(\"   Model: %s\\n\", reranker.ModelIdentifier)\n",
    "            return reranker.RerankerId\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Create new reranker\n",
    "    fmt.Println(\"\ud83d\udcdd Creating new Voyage AI rerank-2.5 reranker...\")\n",
    "    \n",
    "    // Create string variables for NullableString fields\n",
    "    headerName := \"Authorization\"\n",
    "    prefix := \"Bearer \"\n",
    "    apiPath := \"/rerank\"\n",
    "    \n",
    "    credentials := goodmem_client.EndpointAuthentication{\n",
    "        Kind: goodmem_client.CREDENTIAL_KIND_API_KEY,\n",
    "        ApiKey: &goodmem_client.ApiKeyAuth{\n",
    "            InlineSecret: *goodmem_client.NewNullableString(&voyageApiKey),\n",
    "            HeaderName:   *goodmem_client.NewNullableString(&headerName),\n",
    "            Prefix:       *goodmem_client.NewNullableString(&prefix),\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    rerankerRequest := goodmem_client.RerankerCreationRequest{\n",
    "        DisplayName:     \"Voyage Rerank 2.5\",\n",
    "        ProviderType:    \"VOYAGE\",\n",
    "        EndpointUrl:     \"https://api.voyageai.com/v1\",\n",
    "        ModelIdentifier: \"rerank-2.5\",\n",
    "        ApiPath:         *goodmem_client.NewNullableString(&apiPath),\n",
    "        Credentials:     &credentials,\n",
    "    }\n",
    "    \n",
    "    newReranker, httpResp, err := client.RerankersAPI.CreateReranker(ctx).RerankerCreationRequest(rerankerRequest).Execute()\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"\u274c Failed to create reranker: %v (HTTP Status: %d)\\n\", err, httpResp.StatusCode)\n",
    "        return \"\"\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"\u2705 Successfully created Voyage reranker\\n\")\n",
    "    fmt.Printf(\"   Display Name: %s\\n\", newReranker.DisplayName)\n",
    "    fmt.Printf(\"   Reranker ID: %s\\n\", newReranker.RerankerId)\n",
    "    fmt.Printf(\"   Model: %s\\n\", newReranker.ModelIdentifier)\n",
    "    \n",
    "    return newReranker.RerankerId\n",
    "}\n",
    "\n",
    "var voyageRerankerId = cache.Cache(\"voyageRerankerId\", createVoyageReranker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "llm-header",
    "description": "LLM explanation and role in RAG",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Registering an LLM\n",
    "\n",
    "The final component in our RAG pipeline is the **LLM (Large Language Model)** - the generation component that creates natural language responses using the retrieved and reranked context.\n",
    "\n",
    "### Role of LLMs in RAG\n",
    "\n",
    "After retrieving and reranking relevant chunks, the LLM:\n",
    "1. **Receives the query** and retrieved context\n",
    "2. **Generates a response** that synthesizes information from multiple sources\n",
    "3. **Maintains coherence** while staying grounded in the retrieved facts\n",
    "\n",
    "### OpenAI GPT-4o-mini\n",
    "\n",
    "We'll use OpenAI's `gpt-4o-mini` model, which provides:\n",
    "- **Fast inference** with low latency for real-time applications\n",
    "- **Cost-effective** pricing compared to larger models\n",
    "- **High quality** responses suitable for most RAG use cases\n",
    "- **Function calling** support for advanced workflows\n",
    "\n",
    "**Note**: This uses the same `OPENAI_API_KEY` environment variable as the embedder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "cache-reset-llm",
    "description": "Reset gonb cache for openaiLlmId variable",
    "notebook": "go"
   },
   "outputs": [],
   "source": [
    "// Execute to clear gonb cache on openaiLlmId\n",
    "%%\n",
    "cache.ResetKey(\"openaiLlmId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "create-llm",
    "description": "Register OpenAI GPT-4o-mini LLM",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Registering new OpenAI GPT-4o-mini LLM...\n",
      "\u2705 Successfully registered OpenAI LLM\n",
      "   Display Name: OpenAI GPT-4o Mini\n",
      "   LLM ID: 49095c98-e6a0-4d0c-a25c-dfa946f5da49\n",
      "   Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "// Register OpenAI GPT-4o-mini LLM\n",
    "func createOpenAILlm() string {\n",
    "    openaiApiKey := getEnv(\"OPENAI_API_KEY\", \"\")\n",
    "    if openaiApiKey == \"\" {\n",
    "        fmt.Println(\"\u26a0\ufe0f  OPENAI_API_KEY environment variable not set\")\n",
    "        fmt.Println(\"   Please set your OpenAI API key to register an LLM\")\n",
    "        return \"\"\n",
    "    }\n",
    "    \n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    \n",
    "    // Check if LLM already exists\n",
    "    existingLlms, _, _ := client.LLMsAPI.ListLLMs(ctx).Execute()\n",
    "    for _, llm := range existingLlms.Llms {\n",
    "        if llm.ProviderType == \"OPENAI\" && llm.ModelIdentifier == \"gpt-4o-mini\" {\n",
    "            fmt.Printf(\"\u2705 OpenAI LLM already exists\\n\")\n",
    "            fmt.Printf(\"   Display Name: %s\\n\", llm.DisplayName)\n",
    "            fmt.Printf(\"   LLM ID: %s\\n\", llm.LlmId)\n",
    "            fmt.Printf(\"   Model: %s\\n\", llm.ModelIdentifier)\n",
    "            return llm.LlmId\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Create new LLM\n",
    "    fmt.Println(\"\ud83d\udcdd Registering new OpenAI GPT-4o-mini LLM...\")\n",
    "    \n",
    "    // Create string variables for NullableString fields\n",
    "    headerName := \"Authorization\"\n",
    "    prefix := \"Bearer \"\n",
    "    apiPath := \"/chat/completions\"\n",
    "    \n",
    "    credentials := goodmem_client.EndpointAuthentication{\n",
    "        Kind: goodmem_client.CREDENTIAL_KIND_API_KEY,\n",
    "        ApiKey: &goodmem_client.ApiKeyAuth{\n",
    "            InlineSecret: *goodmem_client.NewNullableString(&openaiApiKey),\n",
    "            HeaderName:   *goodmem_client.NewNullableString(&headerName),\n",
    "            Prefix:       *goodmem_client.NewNullableString(&prefix),\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    llmRequest := goodmem_client.LLMCreationRequest{\n",
    "        DisplayName:     \"OpenAI GPT-4o Mini\",\n",
    "        ProviderType:    \"OPENAI\",\n",
    "        EndpointUrl:     \"https://api.openai.com/v1\",\n",
    "        ModelIdentifier: \"gpt-4o-mini\",\n",
    "        ApiPath:         *goodmem_client.NewNullableString(&apiPath),\n",
    "        Capabilities:  goodmem_client.LLMCapabilities{\n",
    "            SupportsChat:               *goodmem_client.NewNullableBool(PtrBool(true)),\n",
    "            SupportsCompletion:         *goodmem_client.NewNullableBool(PtrBool(false)),\n",
    "            SupportsFunctionCalling:    *goodmem_client.NewNullableBool(PtrBool(true)),\n",
    "            SupportsSystemMessages:     *goodmem_client.NewNullableBool(PtrBool(true)),\n",
    "            SupportsStreaming:          *goodmem_client.NewNullableBool(PtrBool(true)),\n",
    "            SupportsSamplingParameters: *goodmem_client.NewNullableBool(PtrBool(true)),\n",
    "        },\n",
    "        Credentials: &credentials,\n",
    "    }\n",
    "    \n",
    "    newLlm, httpResp, err := client.LLMsAPI.CreateLLM(ctx).LLMCreationRequest(llmRequest).Execute()\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"\u274c Failed to register LLM: %v (HTTP Status: %d)\\n\", err, httpResp.StatusCode)\n",
    "        return \"\"\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"\u2705 Successfully registered OpenAI LLM\\n\")\n",
    "    fmt.Printf(\"   Display Name: %s\\n\", newLlm.Llm.DisplayName)\n",
    "    fmt.Printf(\"   LLM ID: %s\\n\", newLlm.Llm.LlmId)\n",
    "    fmt.Printf(\"   Model: %s\\n\", newLlm.Llm.ModelIdentifier)\n",
    "    \n",
    "    return newLlm.Llm.LlmId\n",
    "}\n",
    "\n",
    "var openaiLlmId = cache.Cache(\"openaiLlmId\", createOpenAILlm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "rag-header",
    "description": "Enhanced RAG pipeline explanation",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## Enhanced RAG with Reranking and LLM Generation\n",
    "\n",
    "Now that we have all the components configured (embedder, reranker, and LLM), let's use the complete RAG pipeline! This demonstrates the full power of GoodMem:\n",
    "\n",
    "1. **Retrieval**: Fast semantic search finds relevant chunks\n",
    "2. **Reranking**: Voyage AI reranker re-scores results for better relevance  \n",
    "3. **Generation**: OpenAI GPT-4o-mini generates a coherent response using the reranked context\n",
    "\n",
    "This provides significantly better answer quality compared to simple retrieval alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "rag-pipeline",
    "description": "Complete RAG pipeline with reranking and LLM",
    "notebook": "go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Testing Enhanced RAG Pipeline\n",
      "   Query: What is the vacation policy for employees?\n",
      "   Using reranker: 950de400-8c06-44c9-98d9-9d7ce953afd9\n",
      "   Using LLM: 49095c98-e6a0-4d0c-a25c-dfa946f5da49\n",
      "\n",
      "\ud83d\udd0d Query: What is the vacation policy for employees?\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcdd Generated Answer (streaming):\n",
      "------------------------------------------------------------\n",
      "    Chunk 1: \n",
      "    Relevance: 0.863\n",
      "    Text: TIME OFF POLICY\n",
      "All full-time employees receive:\n",
      "- 15 days of paid vacation annually (increases to 20 days after 3 years)\n",
      "- 10 sick days per year\n",
      "- 8 ...\n",
      "\n",
      "    Chunk 2: \n",
      "    Relevance: 0.730\n",
      "    Text: Vacation requests should be submitted at least 2 weeks in advance through the HR portal. Sick leave can be used for personal illness or to care for im...\n",
      "\n",
      "    Chunk 3: \n",
      "    Relevance: 0.824\n",
      "    Text: [ORGANIZATION] has established the following vacation plan to provide eligible employees \n",
      "time off with pay so that they may be free from their regula...\n",
      "\n",
      "    Chunk 4: \n",
      "    Relevance: 0.777\n",
      "    Text: employees can use paid vacation time in minimum increments of one day.xii \n",
      "\n",
      " \n",
      "Accumulating Vacation: Employees are encouraged to use available paid va...\n",
      "\n",
      "    Chunk 5: \n",
      "    Relevance: 0.770\n",
      "    Text: 1.  Eligibility \n",
      "\n",
      " \n",
      "All regular full-time employees are eligible for vacation benefits. \n",
      "\n",
      " \n",
      "2.  Accrual \n",
      "\n",
      " \n",
      "Eligible employees accrue vacation in acco...\n",
      "\n",
      "    Chunk 6: \n",
      "    Relevance: 0.738\n",
      "    Text: Vacation Pay: Vacation pay shall be based on the employee\u2019s regular base rate and \n",
      "working schedule, exclusive of overtime.  No employee will receiv...\n",
      "\n",
      "    Chunk 7: \n",
      "    Relevance: 0.711\n",
      "    Text: employment classification, they begin to accrue vacation according to the above \n",
      "schedule.  However, there is a waiting period of 90 calendar days (fr...\n",
      "\n",
      "    Chunk 8: \n",
      "    Relevance: 0.691\n",
      "    Text: Vacation Pay on Termination: On termination of employment, each employee will be \n",
      "paid for all accrued but unused vacation.xiii \n",
      " \n",
      "Holiday within a Va...\n",
      "\n",
      "    Chunk 9: \n",
      "    Relevance: 0.656\n",
      "    Text: If they do, however, vacation benefits are deemed a form of deferred compensation, which \u201cvests\u201d as an employee \n",
      "works and which cannot be \u201cforf...\n",
      "\n",
      "    Chunk 10: \n",
      "    Relevance: 0.625\n",
      "    Text: Employees are required to substitute accrued vacation time and other paid personal leave \n",
      "(except sick leave) for all family care, medical, and milita...\n",
      "\n",
      "\n",
      "    LLM Generated Response:\n",
      " The vacation policy for employees states that all full-time employees receive 15 days of paid vacation annually, which increases to 20 days after three years of service. Employees also have 10 sick days per year, 8 company holidays, and personal days as needed with manager approval. Vacation requests must be submitted at least two weeks in advance through the HR portal, and employees accrue vacation time based on their years of continuous service, with a waiting period of 90 calendar days before vacation time can be used.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\u2705 RAG Pipeline completed\n",
      "   Retrieved items: 10\n",
      "   Events processed: 15\n"
     ]
    }
   ],
   "source": [
    "// RagResult represents the complete RAG response\n",
    "type RagResult struct {\n",
    "    Answer         string\n",
    "    RetrievedItems []RetrievedItem\n",
    "    EventCount     int\n",
    "}\n",
    "\n",
    "type RetrievedItem struct {\n",
    "    ChunkText      string\n",
    "    RelevanceScore float64\n",
    "    MemoryIndex    int32\n",
    "}\n",
    "\n",
    "// Complete RAG pipeline with streaming\n",
    "func ragPipelineStreaming(query string, spaceId string, rerankerId string, llmId string, maxResults int32) *RagResult {\n",
    "    if voyageRerankerId == \"\" {\n",
    "        fmt.Println(\"\u26a0\ufe0f  Reranker not available\")\n",
    "        return nil\n",
    "    }\n",
    "    if openaiLlmId == \"\" {\n",
    "        fmt.Println(\"\u26a0\ufe0f  LLM not available\")\n",
    "        return nil\n",
    "    }\n",
    "    \n",
    "    fmt.Printf(\"\ud83d\udd0d Query: %s\\n\", query)\n",
    "    fmt.Println(strings.Repeat(\"=\", 60))\n",
    "    \n",
    "    client := getClient()\n",
    "    ctx := context.Background()\n",
    "    streamingClient := goodmem_client.NewStreamingClient(client)\n",
    "    \n",
    "    // Create advanced streaming request with reranker and LLM\n",
    "    streamReq := &goodmem_client.AdvancedMemoryStreamRequest{\n",
    "        Message:            query,\n",
    "        SpaceIDs:           []string{spaceId},\n",
    "        RequestedSize:      PtrInt32(maxResults),\n",
    "        FetchMemory:        PtrBool(true),\n",
    "        FetchMemoryContent: PtrBool(false),\n",
    "        Format:             goodmem_client.FormatNDJSON,\n",
    "        PostProcessorName:   \"com.goodmem.retrieval.postprocess.ChatPostProcessorFactory\",\n",
    "        PostProcessorConfig: map[string]interface{}{\n",
    "            \"llm_id\":              openaiLlmId,\n",
    "            \"reranker_id\":         voyageRerankerId,\n",
    "            \"relevance_threshold\": 0.3,\n",
    "            \"max_results\":         maxResults,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    // Start streaming\n",
    "    streamCtx, cancel := context.WithTimeout(ctx, 60*time.Second)\n",
    "    defer cancel()\n",
    "    \n",
    "    stream, err := streamingClient.RetrieveMemoryStreamAdvanced(streamCtx, streamReq)\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"\u274c Error during RAG: %v\\n\", err)\n",
    "        return nil\n",
    "    }\n",
    "    \n",
    "    result := &RagResult{\n",
    "        RetrievedItems: []RetrievedItem{},\n",
    "    }\n",
    "    \n",
    "    fmt.Println(\"\\n\ud83d\udcdd Generated Answer (streaming):\")\n",
    "    fmt.Println(strings.Repeat(\"-\", 60))\n",
    "    \n",
    "    for event := range stream {\n",
    "        result.EventCount++\n",
    "        \n",
    "        // Process retrieved chunks\n",
    "        if event.RetrievedItem != nil && event.RetrievedItem.Chunk != nil {\n",
    "            chunkInfo := event.RetrievedItem.Chunk\n",
    "            chunkData := chunkInfo.Chunk\n",
    "            \n",
    "            var chunkText string\n",
    "            if text, ok := chunkData[\"chunkText\"]; ok {\n",
    "                chunkText = fmt.Sprintf(\"%v\", text)\n",
    "            }\n",
    "            \n",
    "            result.RetrievedItems = append(result.RetrievedItems, RetrievedItem{\n",
    "                ChunkText:      chunkText,\n",
    "                RelevanceScore: chunkInfo.RelevanceScore,\n",
    "                MemoryIndex:    int32(chunkInfo.MemoryIndex),\n",
    "            })\n",
    "\n",
    "            fmt.Printf(\"    Chunk %d: \\n\", len(result.RetrievedItems))\n",
    "            fmt.Printf(\"    Relevance: %.3f\\n\", chunkInfo.RelevanceScore)\n",
    "            displayText := chunkText\n",
    "            if len(displayText) > 150 {\n",
    "                displayText = displayText[:150] + \"...\"\n",
    "            }\n",
    "            fmt.Printf(\"    Text: %s\\n\\n\", displayText)\n",
    "        }\n",
    "        \n",
    "        // Process LLM response chunks\n",
    "        if event.AbstractReply != nil {\n",
    "            result.Answer = event.AbstractReply.GetText()\n",
    "            fmt.Printf(\"\\n    LLM Generated Response:\\n %s\\n\", result.Answer)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fmt.Println(\"\\n\" + strings.Repeat(\"-\", 60))\n",
    "    fmt.Printf(\"\\n\u2705 RAG Pipeline completed\\n\")\n",
    "    fmt.Printf(\"   Retrieved items: %d\\n\", len(result.RetrievedItems))\n",
    "    fmt.Printf(\"   Events processed: %d\\n\", result.EventCount)\n",
    "    \n",
    "    return result\n",
    "}\n",
    "\n",
    "%%\n",
    "// Test the complete RAG pipeline\n",
    "testQuery := \"What is the vacation policy for employees?\"\n",
    "fmt.Printf(\"\ud83d\ude80 Testing Enhanced RAG Pipeline\\n\")\n",
    "fmt.Printf(\"   Query: %s\\n\", testQuery)\n",
    "fmt.Printf(\"   Using reranker: %s\\n\", voyageRerankerId)\n",
    "fmt.Printf(\"   Using LLM: %s\\n\", openaiLlmId)\n",
    "fmt.Println()\n",
    "\n",
    "ragPipelineStreaming(\n",
    "    testQuery,\n",
    "    demoSpaceId,\n",
    "    voyageRerankerId,\n",
    "    openaiLlmId,\n",
    "    10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "conclusion",
    "description": "Tutorial completion and next steps",
    "language_dependent": false,
    "notebook": "go"
   },
   "source": [
    "## \ud83c\udf89 Congratulations! What You Built\n",
    "\n",
    "You've successfully built a complete **Retrieval-Augmented Generation (RAG) system** using GoodMem! Let's recap what you accomplished.\n",
    "\n",
    "### Components You Configured\n",
    "\n",
    "| Component | Purpose | Function |\n",
    "|-----------|---------|----------|\n",
    "| **Embedder** | Convert text to vectors | Transform documents into semantic embeddings |\n",
    "| **Space** | Organize and store documents | Logical container with chunking configuration |\n",
    "| **Memories** | Store searchable content | Documents chunked and indexed for retrieval |\n",
    "| **Reranker** | Improve search precision | Re-score results for better relevance |\n",
    "| **LLM** | Generate natural language | Create coherent answers from retrieved context |\n",
    "\n",
    "### The Complete RAG Pipeline\n",
    "\n",
    "```\n",
    "\ud83d\udcc4 Documents\n",
    "   \u2193 Chunking (256 chars, 25 overlap)\n",
    "   \u2193 Embedding (convert to vectors)\n",
    "\ud83d\uddc4\ufe0f  Vector Storage (GoodMem Space)\n",
    "   \u2193 \n",
    "\ud83d\udd0d User Query\n",
    "   \u2193 Semantic Search (retrieve top-K)\n",
    "   \u2193 Reranking (re-score for precision)\n",
    "   \u2193 Context Selection (most relevant chunks)\n",
    "\ud83e\udd16 LLM Generation (synthesize answer)\n",
    "   \u2193\n",
    "\u2728 Natural Language Answer\n",
    "```\n",
    "\n",
    "### Key Concepts You Learned\n",
    "\n",
    "1. **Embedders**: Transform text into semantic vectors for similarity search\n",
    "2. **Spaces**: Logical containers for organizing and searching documents\n",
    "3. **Chunking**: Breaking documents into optimal sizes for retrieval\n",
    "4. **Semantic Search**: Finding conceptually similar content, not just keyword matches\n",
    "5. **Reranking**: Two-stage retrieval for better precision\n",
    "6. **Streaming API**: Real-time, memory-efficient result processing\n",
    "7. **RAG Architecture**: Combining retrieval and generation for accurate, grounded responses\n",
    "\n",
    "### Performance Improvements\n",
    "\n",
    "**Basic search** (retrieval only):\n",
    "- Fast retrieval using vector similarity\n",
    "- Good recall, but may include less relevant results\n",
    "\n",
    "**Enhanced RAG** (with reranker + LLM):\n",
    "- Reranker improves precision significantly\n",
    "- LLM synthesizes information from multiple chunks\n",
    "- Better user experience with natural language answers\n",
    "- Grounded in actual document content (no hallucinations)\n",
    "\n",
    "### Next Steps & Advanced Topics\n",
    "\n",
    "**Enhance Your RAG System**:\n",
    "- **Multiple embedders**: Combine different embedders for better coverage\n",
    "- **Custom chunking**: Tune chunk size/overlap for your content type\n",
    "- **Metadata filtering**: Add filters to narrow search by document type, date, etc.\n",
    "- **Hybrid search**: Combine semantic and keyword search\n",
    "- **Context augmentation**: Include surrounding chunks for better LLM context\n",
    "\n",
    "**Production Deployment**:\n",
    "- **Monitoring**: Track query latency, relevance scores, user feedback\n",
    "- **Scaling**: Horizontal scaling for high-traffic applications\n",
    "- **Cost optimization**: Balance quality vs. API costs\n",
    "- **Caching**: Cache frequent queries for faster responses\n",
    "- **Error handling**: Robust exception handling and retry logic\n",
    "\n",
    "**Advanced Features**:\n",
    "- **Multi-space search**: Query across multiple knowledge bases\n",
    "- **Query expansion**: Transform queries for better retrieval\n",
    "- **Result aggregation**: Combine and deduplicate results\n",
    "- **Streaming generation**: Progressive LLM responses for real-time UX\n",
    "- **Fine-tuning**: Customize models for your specific domain\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Documentation**: [https://docs.goodmem.ai](https://docs.goodmem.ai)\n",
    "- **Community**: Join discussions and share your implementations\n",
    "- **Examples**: Explore more advanced use cases and patterns\n",
    "\n",
    "---\n",
    "\n",
    "**Great job!** You now have a solid foundation for building production RAG systems with GoodMem. \ud83d\ude80\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "text/x-go",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.24.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
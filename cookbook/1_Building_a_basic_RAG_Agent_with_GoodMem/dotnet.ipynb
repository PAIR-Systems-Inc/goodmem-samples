{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "intro",
    "description": "Introduction to building RAG with GoodMem",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "# Building a Basic RAG Agent with GoodMem\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial will guide you through building a complete **Retrieval-Augmented Generation (RAG)** system using GoodMem's vector memory capabilities. By the end of this guide, you'll have a functional Q&A system that can:\n",
    "\n",
    "- üîç **Semantically search** through your documents\n",
    "- üìù **Generate contextual answers** using retrieved information \n",
    "- üèóÔ∏è **Scale to handle** large document collections\n",
    "\n",
    "### What is RAG?\n",
    "\n",
    "RAG combines the power of **retrieval** (finding relevant information) with **generation** (creating natural language responses). This approach allows AI systems to provide accurate, context-aware answers by:\n",
    "\n",
    "1. **Retrieving** relevant documents from a knowledge base\n",
    "2. **Augmenting** the query with this context\n",
    "3. **Generating** a comprehensive answer using both the query and retrieved information\n",
    "\n",
    "### Why GoodMem for RAG?\n",
    "\n",
    "GoodMem provides enterprise-grade vector storage with:\n",
    "- **Multiple embedder support** for optimal retrieval accuracy\n",
    "- **Streaming APIs** for real-time responses\n",
    "- **Advanced post-processing** with reranking and summarization\n",
    "- **Scalable architecture** for production workloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "prerequisites",
    "description": "Prerequisites for C# tutorial",
    "language_dependent": true,
    "notebook": "dotnet"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "- ‚úÖ **GoodMem server running** (install with: `curl -s https://get.goodmem.ai | bash`)\n",
    "- ‚úÖ **.NET 6.0+ SDK** installed\n",
    "- ‚úÖ **NuGet package manager** for dependency management\n",
    "- ‚úÖ **API key** for your GoodMem instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "installation-header",
    "description": "Installation and setup header",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Installation & Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Newtonsoft.Json, 13.0.2</span></li><li><span>Pairsystems.Goodmem.Client, 1.0.6</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Packages installed:\n",
      "   - Pairsystems.Goodmem.Client (v1.0.6)\n",
      "   - Newtonsoft.Json\n",
      "\n",
      "üí° Make sure .NET 6.0+ SDK is installed\n"
     ]
    }
   ],
   "source": [
    "// Install required NuGet packages\n",
    "#r \"nuget: Pairsystems.Goodmem.Client, 1.0.6\"\n",
    "#r \"nuget: Newtonsoft.Json, 13.0.2\"\n",
    "\n",
    "Console.WriteLine(\"üì¶ Packages installed:\");\n",
    "Console.WriteLine(\"   - Pairsystems.Goodmem.Client (v1.0.6)\");\n",
    "Console.WriteLine(\"   - Newtonsoft.Json\");\n",
    "Console.WriteLine(\"\\nüí° Make sure .NET 6.0+ SDK is installed\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "auth-header",
    "description": "Authentication and configuration explanation",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Authentication & Configuration\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "GoodMem uses API key authentication to secure your vector memory data. Proper configuration ensures:\n",
    "- **Secure access** to your GoodMem instance\n",
    "- **Isolated environments** (development, staging, production)\n",
    "- **Usage tracking** and access control per API key\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Configure the GoodMem host URL (where your server is running)\n",
    "2. Set up API key authentication\n",
    "3. Verify the configuration is correct\n",
    "\n",
    "### Configuration Options\n",
    "\n",
    "- **Local development**: `http://localhost:8080` (default)\n",
    "- **Remote/production**: Your deployed GoodMem URL\n",
    "- **Environment variables**: Best practice for managing credentials\n",
    "\n",
    "Let's configure our GoodMem client and test the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoodMem Host: http://localhost:8080\n",
      "API Key configured: Yes\n",
      "‚úÖ GoodMem client configured successfully!\n"
     ]
    }
   ],
   "source": [
    "using System;\n",
    "using System.Collections.Generic;\n",
    "using System.IO;\n",
    "using System.Linq;\n",
    "using System.Threading;\n",
    "using System.Threading.Tasks;\n",
    "using Pairsystems.Goodmem.Client;\n",
    "using Pairsystems.Goodmem.Client.Api;\n",
    "using Pairsystems.Goodmem.Client.Client;\n",
    "using Pairsystems.Goodmem.Client.Model;\n",
    "\n",
    "// Configuration - Update these values for your setup\n",
    "var GOODMEM_HOST = Environment.GetEnvironmentVariable(\"GOODMEM_HOST\") ?? \"http://localhost:8080\";\n",
    "var GOODMEM_API_KEY = Environment.GetEnvironmentVariable(\"GOODMEM_API_KEY\") ?? \"\";\n",
    "\n",
    "Console.WriteLine($\"GoodMem Host: {GOODMEM_HOST}\");\n",
    "Console.WriteLine($\"API Key configured: {(GOODMEM_API_KEY != \"your-api-key-here\" ? \"Yes\" : \"No - Please update\")}\");\n",
    "\n",
    "// Create and configure API client\n",
    "var config = new Configuration();\n",
    "config.BasePath = GOODMEM_HOST;\n",
    "config.DefaultHeaders[\"X-API-Key\"] = GOODMEM_API_KEY;\n",
    "\n",
    "// Create API instances\n",
    "var spacesApi = new SpacesApi(config);\n",
    "var memoriesApi = new MemoriesApi(config);\n",
    "var embeddersApi = new EmbeddersApi(config);\n",
    "\n",
    "Console.WriteLine(\"‚úÖ GoodMem client configured successfully!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to GoodMem!\n",
      "   Found 0 existing spaces\n"
     ]
    }
   ],
   "source": [
    "// Test connection by listing existing spaces\n",
    "try\n",
    "{\n",
    "    var response = await spacesApi.ListSpacesAsync();\n",
    "    \n",
    "    Console.WriteLine(\"‚úÖ Successfully connected to GoodMem!\");\n",
    "    var spaces = response.Spaces ?? new List<Space>();\n",
    "    Console.WriteLine($\"   Found {spaces.Count} existing spaces\");\n",
    "}\n",
    "catch (ApiException e)\n",
    "{\n",
    "    Console.WriteLine($\"‚ùå Error connecting to GoodMem: {e.Message}\");\n",
    "    Console.WriteLine(\"   Please check your API key and host configuration\");\n",
    "    Console.WriteLine($\"   Response code: {e.ErrorCode}\");\n",
    "}\n",
    "catch (Exception e)\n",
    "{\n",
    "    Console.WriteLine($\"‚ùå Unexpected error: {e.Message}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "embedder-header",
    "description": "Embedder explanation and concepts",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Creating an Embedder\n",
    "\n",
    "### Why Embedders Matter\n",
    "\n",
    "An **embedder** is the foundation of semantic search. It converts text into high-dimensional vectors (embeddings) that capture meaning:\n",
    "\n",
    "```\n",
    "Text: \"vacation policy\" ‚Üí Vector: [0.23, -0.45, 0.67, ...]  (1536 dimensions)\n",
    "```\n",
    "\n",
    "These vectors enable:\n",
    "- **Semantic similarity**: Find conceptually similar content, not just keyword matches\n",
    "- **Context understanding**: Capture meaning beyond exact word matches\n",
    "- **Efficient retrieval**: Fast vector comparisons using specialized indexes\n",
    "\n",
    "### The RAG Pipeline Flow\n",
    "\n",
    "```\n",
    "Documents ‚Üí Embedder ‚Üí Vector Storage ‚Üí Semantic Search ‚Üí Retrieved Context\n",
    "```\n",
    "\n",
    "### Choosing an Embedder\n",
    "\n",
    "**OpenAI `text-embedding-3-small`** (what we'll use):\n",
    "- ‚úÖ **High quality**: Excellent for most use cases\n",
    "- ‚úÖ **Fast**: Low latency for real-time applications  \n",
    "- ‚úÖ **1536 dimensions**: Good balance of quality and storage\n",
    "- ‚úÖ **Cost-effective**: $0.02 per 1M tokens\n",
    "\n",
    "**Other options**:\n",
    "- **text-embedding-3-large**: Higher quality, 3072 dimensions, more expensive\n",
    "- **Voyage AI**: Specialized for search, excellent retrieval performance\n",
    "- **Cohere**: Good multilingual support\n",
    "- **Local models**: HuggingFace sentence transformers for privacy/offline\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Check if an embedder already exists\n",
    "2. If not, create an OpenAI embedder with proper authentication\n",
    "3. Verify the embedder is ready for use\n",
    "\n",
    "**Note**: You'll need an OpenAI API key set in your environment variable `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating new OpenAI embedder...\n",
      "‚úÖ Successfully created OpenAI embedder!\n",
      "   Display Name: OpenAI Text Embedding 3 Small\n",
      "   Embedder ID: 645cf99e-d03f-4d75-845d-f263f20fe3ab\n",
      "   Provider: OPENAI\n",
      "   Model: text-embedding-3-small\n",
      "   Dimensionality: 1536\n"
     ]
    }
   ],
   "source": [
    "// Create or retrieve OpenAI embedder\n",
    "EmbedderResponse openaiEmbedder = null;\n",
    "\n",
    "var openaiApiKey = Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\") ?? \"\";\n",
    "\n",
    "if (string.IsNullOrEmpty(openaiApiKey))\n",
    "{\n",
    "    Console.WriteLine(\"‚ùå OPENAI_API_KEY environment variable not set!\");\n",
    "    Console.WriteLine(\"   Please set your OpenAI API key:\");\n",
    "    Console.WriteLine(\"   export OPENAI_API_KEY='your-api-key-here'\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        // Check if embedder already exists\n",
    "        var embeddersResponse = await embeddersApi.ListEmbeddersAsync();\n",
    "        var existingEmbedders = embeddersResponse.Embedders?.ToList() ?? new List<EmbedderResponse>();\n",
    "\n",
    "        var existingEmbedder = existingEmbedders.FirstOrDefault(e =>\n",
    "            e.ProviderType.ToString() == \"OPENAI\" &&\n",
    "            e.ModelIdentifier == \"text-embedding-3-small\");\n",
    "\n",
    "        if (existingEmbedder != null)\n",
    "        {\n",
    "            openaiEmbedder = existingEmbedder;\n",
    "            Console.WriteLine(\"‚úÖ OpenAI embedder already exists!\");\n",
    "            Console.WriteLine($\"   Display Name: {openaiEmbedder.DisplayName}\");\n",
    "            Console.WriteLine($\"   Embedder ID: {openaiEmbedder.EmbedderId}\");\n",
    "            Console.WriteLine($\"   Model: {openaiEmbedder.ModelIdentifier}\");\n",
    "            Console.WriteLine($\"   Dimensionality: {openaiEmbedder.Dimensionality}\");\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            Console.WriteLine(\"üîß Creating new OpenAI embedder...\");\n",
    "\n",
    "            // Create API key authentication\n",
    "            var apiKeyAuth = new ApiKeyAuth\n",
    "            {\n",
    "                InlineSecret = openaiApiKey,\n",
    "                HeaderName = \"Authorization\",\n",
    "                Prefix = \"Bearer \"\n",
    "            };\n",
    "\n",
    "            var credentials = new EndpointAuthentication\n",
    "            {\n",
    "                Kind = CredentialKind.CREDENTIALKINDAPIKEY,\n",
    "                ApiKey = apiKeyAuth\n",
    "            };\n",
    "\n",
    "            // Create embedder request\n",
    "            var embedderRequest = new EmbedderCreationRequest(\n",
    "                displayName: \"OpenAI Text Embedding 3 Small\",\n",
    "                providerType: ProviderType.OPENAI,\n",
    "                endpointUrl: \"https://api.openai.com/v1\",\n",
    "                modelIdentifier: \"text-embedding-3-small\",\n",
    "                dimensionality: 1536,\n",
    "                apiPath: \"/embeddings\",\n",
    "                distributionType: DistributionType.DENSE,\n",
    "                credentials: credentials\n",
    "            );\n",
    "\n",
    "            var newEmbedder = await embeddersApi.CreateEmbedderAsync(embedderRequest);\n",
    "            openaiEmbedder = newEmbedder;\n",
    "\n",
    "            Console.WriteLine(\"‚úÖ Successfully created OpenAI embedder!\");\n",
    "            Console.WriteLine($\"   Display Name: {openaiEmbedder.DisplayName}\");\n",
    "            Console.WriteLine($\"   Embedder ID: {openaiEmbedder.EmbedderId}\");\n",
    "            Console.WriteLine($\"   Provider: {openaiEmbedder.ProviderType}\");\n",
    "            Console.WriteLine($\"   Model: {openaiEmbedder.ModelIdentifier}\");\n",
    "            Console.WriteLine($\"   Dimensionality: {openaiEmbedder.Dimensionality}\");\n",
    "        }\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error creating embedder: {e.Message}\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "space-header",
    "description": "Space concept and chunking explanation",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Creating Your First Space\n",
    "\n",
    "### What is a Space?\n",
    "\n",
    "A **Space** in GoodMem is a logical container for organizing related memories (documents). Think of it as a database or collection where you store and retrieve semantically similar content.\n",
    "\n",
    "Each space has:\n",
    "- **Associated embedders**: Which models convert text to vectors\n",
    "- **Chunking configuration**: How documents are split into searchable pieces\n",
    "- **Access controls**: Public or private, with permission management\n",
    "- **Metadata labels**: For organization and filtering\n",
    "\n",
    "### Use Cases for Multiple Spaces\n",
    "\n",
    "You might create different spaces for:\n",
    "- **By domain**: Technical docs, HR policies, product specs\n",
    "- **By environment**: Development, staging, production\n",
    "- **By customer**: Tenant-specific data in multi-tenant apps\n",
    "- **By privacy level**: Public FAQ vs. internal knowledge base\n",
    "\n",
    "### Why Chunking Matters\n",
    "\n",
    "Documents are too large to search efficiently as whole units. Chunking:\n",
    "- **Improves relevance**: Match specific sections, not entire documents\n",
    "- **Enables context**: Return focused chunks that answer specific questions  \n",
    "- **Optimizes retrieval**: Process and compare smaller text segments\n",
    "\n",
    "**Our chunking strategy**:\n",
    "- **256 characters**: Short enough for focused context, long enough for meaning\n",
    "- **25 character overlap**: Ensures concepts spanning chunk boundaries aren't lost\n",
    "- **Hierarchical separators**: Split on paragraphs first, then sentences, then words\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. List available embedders\n",
    "2. Create a space with our embedder and chunking configuration\n",
    "3. Add metadata labels for organization\n",
    "4. Verify the space is ready\n",
    "\n",
    "Let's create a space for our RAG demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available Embedders (1):\n",
      "   1. OpenAI Text Embedding 3 Small - OPENAI\n",
      "      Model: text-embedding-3-small\n",
      "      ID: 645cf99e-d03f-4d75-845d-f263f20fe3ab\n",
      "\n",
      "üéØ Using embedder: OpenAI Text Embedding 3 Small\n"
     ]
    }
   ],
   "source": [
    "// First, let's see what embedders are available\n",
    "List<EmbedderResponse> availableEmbedders = new List<EmbedderResponse>();\n",
    "EmbedderResponse defaultEmbedder = null;\n",
    "\n",
    "try\n",
    "{\n",
    "    var embeddersResponse = await embeddersApi.ListEmbeddersAsync();\n",
    "    availableEmbedders = embeddersResponse.Embedders?.ToList() ?? new List<EmbedderResponse>();\n",
    "    \n",
    "    Console.WriteLine($\"üìã Available Embedders ({availableEmbedders.Count}):\");\n",
    "    for (int i = 0; i < availableEmbedders.Count; i++)\n",
    "    {\n",
    "        var embedder = availableEmbedders[i];\n",
    "        Console.WriteLine($\"   {i + 1}. {embedder.DisplayName} - {embedder.ProviderType}\");\n",
    "        Console.WriteLine($\"      Model: {embedder.ModelIdentifier ?? \"N/A\"}\");\n",
    "        Console.WriteLine($\"      ID: {embedder.EmbedderId}\");\n",
    "        Console.WriteLine();\n",
    "    }\n",
    "    \n",
    "    if (availableEmbedders.Any())\n",
    "    {\n",
    "        defaultEmbedder = availableEmbedders[0];\n",
    "        Console.WriteLine($\"üéØ Using embedder: {defaultEmbedder.DisplayName}\");\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        Console.WriteLine(\"‚ö†Ô∏è  No embedders found. You may need to configure an embedder first.\");\n",
    "        Console.WriteLine(\"   Refer to the documentation: https://docs.goodmem.ai/docs/reference/cli/goodmem_embedder_create/\");\n",
    "    }\n",
    "}\n",
    "catch (ApiException e)\n",
    "{\n",
    "    Console.WriteLine($\"‚ùå Error listing embedders: {e.Message}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Demo Chunking Configuration:\n",
      "   Chunk Size: 256 characters\n",
      "   Overlap: 25 characters\n",
      "   Strategy: KEEPEND\n",
      "   üí° This chunking config will be reused for all memory creation!\n",
      "\n",
      "‚úÖ Created space: RAG Demo Knowledge Base (C#)\n",
      "   Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "   Embedders: 1\n",
      "   Labels: purpose=rag-demo, environment=tutorial, content-type=documentation, language=csharp\n",
      "   Chunking Config Saved: 256 chars with 25 overlap\n"
     ]
    }
   ],
   "source": [
    "// Create a space for our RAG demo\n",
    "var SPACE_NAME = \"RAG Demo Knowledge Base (C#)\";\n",
    "Space demoSpace = null;\n",
    "\n",
    "// Define chunking configuration that we'll reuse throughout the tutorial\n",
    "var recursiveConfig = new RecursiveChunkingConfiguration(\n",
    "    chunkSize: 256,\n",
    "    chunkOverlap: 25,\n",
    "    separators: new List<string> { \"\\n\\n\", \"\\n\", \". \", \" \", \"\" },\n",
    "    keepStrategy: SeparatorKeepStrategy.KEEPEND,\n",
    "    separatorIsRegex: false,\n",
    "    lengthMeasurement: LengthMeasurement.CHARACTERCOUNT\n",
    ");\n",
    "\n",
    "var DEMO_CHUNKING_CONFIG = new ChunkingConfiguration(\n",
    "    recursive: recursiveConfig\n",
    ");\n",
    "\n",
    "Console.WriteLine(\"üìã Demo Chunking Configuration:\");\n",
    "Console.WriteLine($\"   Chunk Size: {DEMO_CHUNKING_CONFIG.Recursive.ChunkSize} characters\");\n",
    "Console.WriteLine($\"   Overlap: {DEMO_CHUNKING_CONFIG.Recursive.ChunkOverlap} characters\");\n",
    "Console.WriteLine($\"   Strategy: {DEMO_CHUNKING_CONFIG.Recursive.KeepStrategy}\");\n",
    "Console.WriteLine(\"   üí° This chunking config will be reused for all memory creation!\");\n",
    "Console.WriteLine();\n",
    "\n",
    "try\n",
    "{\n",
    "    // Check if space already exists\n",
    "    var existingSpaces = await spacesApi.ListSpacesAsync();\n",
    "    \n",
    "    if (existingSpaces.Spaces != null)\n",
    "    {\n",
    "        foreach (var space in existingSpaces.Spaces)\n",
    "        {\n",
    "            if (space.Name == SPACE_NAME)\n",
    "            {\n",
    "                Console.WriteLine($\"üìÅ Space '{SPACE_NAME}' already exists\");\n",
    "                Console.WriteLine($\"   Space ID: {space.SpaceId}\");\n",
    "                Console.WriteLine(\"   To remove existing space, see https://docs.goodmem.ai/docs/reference/cli/goodmem_space_delete/\");\n",
    "                demoSpace = space;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Create space if it doesn't exist\n",
    "    if (demoSpace == null)\n",
    "    {\n",
    "        var spaceEmbedders = new List<SpaceEmbedderConfig>();\n",
    "        if (defaultEmbedder != null)\n",
    "        {\n",
    "            var embedderConfig = new SpaceEmbedderConfig(\n",
    "                embedderId: defaultEmbedder.EmbedderId,\n",
    "                defaultRetrievalWeight: 1.0\n",
    "            );\n",
    "            spaceEmbedders.Add(embedderConfig);\n",
    "        }\n",
    "        \n",
    "        var createRequest = new SpaceCreationRequest(\n",
    "            name: SPACE_NAME,\n",
    "            labels: new Dictionary<string, string>\n",
    "            {\n",
    "                [\"purpose\"] = \"rag-demo\",\n",
    "                [\"environment\"] = \"tutorial\",\n",
    "                [\"content-type\"] = \"documentation\",\n",
    "                [\"language\"] = \"csharp\"\n",
    "            },\n",
    "            spaceEmbedders: spaceEmbedders,\n",
    "            publicRead: false,\n",
    "            defaultChunkingConfig: DEMO_CHUNKING_CONFIG\n",
    "        );\n",
    "        \n",
    "        demoSpace = await spacesApi.CreateSpaceAsync(createRequest);\n",
    "        \n",
    "        Console.WriteLine($\"‚úÖ Created space: {demoSpace.Name}\");\n",
    "        Console.WriteLine($\"   Space ID: {demoSpace.SpaceId}\");\n",
    "        Console.WriteLine($\"   Embedders: {demoSpace.SpaceEmbedders?.Count ?? 0}\");\n",
    "        Console.WriteLine($\"   Labels: {string.Join(\", \", demoSpace.Labels.Select(kv => $\"{kv.Key}={kv.Value}\"))}\");\n",
    "        Console.WriteLine($\"   Chunking Config Saved: {DEMO_CHUNKING_CONFIG.Recursive.ChunkSize} chars with {DEMO_CHUNKING_CONFIG.Recursive.ChunkOverlap} overlap\");\n",
    "    }\n",
    "}\n",
    "catch (ApiException e)\n",
    "{\n",
    "    Console.WriteLine($\"‚ùå Error creating space: {e.Message}\");\n",
    "    Console.WriteLine($\"   Response code: {e.ErrorCode}\");\n",
    "}\n",
    "catch (Exception e)\n",
    "{\n",
    "    Console.WriteLine($\"‚ùå Unexpected error: {e.Message}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Space Configuration:\n",
      "   Name: RAG Demo Knowledge Base (C#)\n",
      "   Owner ID: cf5df949-31c6-4c54-af50-f8002107164e\n",
      "   Public Read: False\n",
      "   Created: 12/11/2025 12:48:37‚ÄØAM\n",
      "   Labels: purpose=rag-demo, language=csharp, environment=tutorial, content-type=documentation\n",
      "\n",
      "ü§ñ Associated Embedders:\n",
      "   Embedder ID: 645cf99e-d03f-4d75-845d-f263f20fe3ab\n",
      "   Retrieval Weight: 1\n"
     ]
    }
   ],
   "source": [
    "// Verify our space configuration\n",
    "if (demoSpace != null)\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        var spaceDetails = await spacesApi.GetSpaceAsync(demoSpace.SpaceId);\n",
    "        \n",
    "        Console.WriteLine(\"üîç Space Configuration:\");\n",
    "        Console.WriteLine($\"   Name: {spaceDetails.Name}\");\n",
    "        Console.WriteLine($\"   Owner ID: {spaceDetails.OwnerId}\");\n",
    "        Console.WriteLine($\"   Public Read: {spaceDetails.PublicRead}\");\n",
    "        Console.WriteLine($\"   Created: {DateTimeOffset.FromUnixTimeMilliseconds(spaceDetails.CreatedAt).DateTime}\");\n",
    "        Console.WriteLine($\"   Labels: {string.Join(\", \", spaceDetails.Labels.Select(kv => $\"{kv.Key}={kv.Value}\"))}\");\n",
    "        \n",
    "        Console.WriteLine(\"\\nü§ñ Associated Embedders:\");\n",
    "        if (spaceDetails.SpaceEmbedders != null && spaceDetails.SpaceEmbedders.Any())\n",
    "        {\n",
    "            foreach (var embedderAssoc in spaceDetails.SpaceEmbedders)\n",
    "            {\n",
    "                Console.WriteLine($\"   Embedder ID: {embedderAssoc.EmbedderId}\");\n",
    "                Console.WriteLine($\"   Retrieval Weight: {embedderAssoc.DefaultRetrievalWeight}\");\n",
    "            }\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            Console.WriteLine(\"   No embedders configured\");\n",
    "        }\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error getting space details: {e.Message}\");\n",
    "    }\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  No space available for the demo\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "documents-header",
    "description": "Document processing pipeline explanation",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Adding Documents to Memory\n",
    "\n",
    "### The Document Processing Pipeline\n",
    "\n",
    "When you add a document to GoodMem, it goes through several automated steps:\n",
    "\n",
    "```\n",
    "1. Ingestion ‚Üí 2. Chunking ‚Üí 3. Embedding ‚Üí 4. Indexing ‚Üí 5. Ready for Search\n",
    "```\n",
    "\n",
    "**What happens**:\n",
    "1. **Ingestion**: Document content and metadata are stored\n",
    "2. **Chunking**: Text is split according to your configuration (256 chars, 25 overlap)\n",
    "3. **Embedding**: Each chunk is converted to a vector by your embedder\n",
    "4. **Indexing**: Vectors are indexed for fast similarity search\n",
    "5. **Status**: Document marked as `COMPLETED` and ready for retrieval\n",
    "\n",
    "### Single vs. Batch Operations\n",
    "\n",
    "**Single memory creation** (`CreateMemory`):\n",
    "- ‚úÖ Good for: Real-time ingestion, single documents\n",
    "- ‚úÖ Synchronous processing with immediate status\n",
    "- ‚ö†Ô∏è Higher overhead for bulk operations\n",
    "\n",
    "**Batch memory creation** (`BatchCreateMemory`):\n",
    "- ‚úÖ Good for: Bulk imports, initial setup, periodic updates\n",
    "- ‚úÖ Lower overhead, efficient for multiple documents\n",
    "- ‚úÖ Async processing - check status via `ListMemories`\n",
    "- ‚ö†Ô∏è Takes longer to get individual status feedback\n",
    "\n",
    "### Metadata Best Practices\n",
    "\n",
    "Rich metadata helps with:\n",
    "- **Filtering**: Retrieve specific document types\n",
    "- **Source attribution**: Show users where information came from\n",
    "- **Organization**: Group and manage related documents\n",
    "- **Debugging**: Track ingestion methods and dates\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Load sample documents from local files\n",
    "2. Create one document using single memory creation (to demo the API)\n",
    "3. Create remaining documents using batch operation (more efficient)\n",
    "4. Monitor processing status until all documents are ready\n",
    "\n",
    "We'll use sample company documents that represent common business use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded: company_handbook.txt (2,342 characters)\n",
      "üìÑ Loaded: employee_handbook.pdf (399,615 bytes, base64: 532,820 chars)\n",
      "üìÑ Loaded: product_faq.txt (4,043 characters)\n",
      "üìÑ Loaded: security_policy.txt (4,211 characters)\n",
      "üìÑ Loaded: technical_documentation.txt (2,384 characters)\n",
      "\n",
      "üìö Total documents loaded: 5\n"
     ]
    }
   ],
   "source": [
    "// Helper class to hold document information\n",
    "public class DocumentInfo\n",
    "{\n",
    "    public string Filename { get; set; }\n",
    "    public string Content { get; set; }\n",
    "    public string ContentB64 { get; set; }\n",
    "    public string ContentType { get; set; }\n",
    "    public bool IsBinary { get; set; }\n",
    "}\n",
    "\n",
    "// Load our sample documents with auto-discovery\n",
    "async Task<List<DocumentInfo>> LoadSampleDocuments()\n",
    "{\n",
    "    /**\n",
    "     * Load sample documents from the sample_documents directory.\n",
    "     * \n",
    "     * Automatically discovers all files in the directory and handles:\n",
    "     * - .txt files: Read as plain text\n",
    "     * - .pdf files: Read as binary and base64 encode\n",
    "     */\n",
    "    var documents = new List<DocumentInfo>();\n",
    "    var sampleDir = \"sample_documents\";\n",
    "    \n",
    "    // Check if directory exists\n",
    "    if (!Directory.Exists(sampleDir))\n",
    "    {\n",
    "        Console.WriteLine($\"‚ö†Ô∏è  Directory not found: {sampleDir}\");\n",
    "        return documents;\n",
    "    }\n",
    "    \n",
    "    try\n",
    "    {\n",
    "        // Auto-discover and sort files\n",
    "        var files = Directory.GetFiles(sampleDir).OrderBy(f => f).ToArray();\n",
    "        \n",
    "        foreach (var filepath in files)\n",
    "        {\n",
    "            var filename = Path.GetFileName(filepath);\n",
    "            var fileExt = Path.GetExtension(filename).ToLower();\n",
    "            \n",
    "            if (fileExt == \".txt\")\n",
    "            {\n",
    "                // Handle text files\n",
    "                try\n",
    "                {\n",
    "                    var content = await File.ReadAllTextAsync(filepath);\n",
    "                    documents.Add(new DocumentInfo\n",
    "                    {\n",
    "                        Filename = filename,\n",
    "                        Content = content,\n",
    "                        ContentType = \"text/plain\",\n",
    "                        IsBinary = false\n",
    "                    });\n",
    "                    Console.WriteLine($\"üìÑ Loaded: {filename} ({content.Length:N0} characters)\");\n",
    "                }\n",
    "                catch (Exception e)\n",
    "                {\n",
    "                    Console.WriteLine($\"‚ö†Ô∏è  Error reading {filename}: {e.Message}\");\n",
    "                }\n",
    "            }\n",
    "            else if (fileExt == \".pdf\")\n",
    "            {\n",
    "                // Handle PDF files with base64 encoding\n",
    "                try\n",
    "                {\n",
    "                    var binaryContent = await File.ReadAllBytesAsync(filepath);\n",
    "                    var contentB64 = Convert.ToBase64String(binaryContent);\n",
    "                    documents.Add(new DocumentInfo\n",
    "                    {\n",
    "                        Filename = filename,\n",
    "                        ContentB64 = contentB64,\n",
    "                        ContentType = \"application/pdf\",\n",
    "                        IsBinary = true\n",
    "                    });\n",
    "                    Console.WriteLine($\"üìÑ Loaded: {filename} ({binaryContent.Length:N0} bytes, base64: {contentB64.Length:N0} chars)\");\n",
    "                }\n",
    "                catch (Exception e)\n",
    "                {\n",
    "                    Console.WriteLine($\"‚ö†Ô∏è  Error reading {filename}: {e.Message}\");\n",
    "                }\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "                Console.WriteLine($\"‚ö†Ô∏è  Skipping unsupported file type: {filename}\");\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    catch (Exception e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error listing directory: {e.Message}\");\n",
    "    }\n",
    "    \n",
    "    return documents;\n",
    "}\n",
    "\n",
    "// Load the documents\n",
    "var sampleDocs = await LoadSampleDocuments();\n",
    "Console.WriteLine($\"\\nüìö Total documents loaded: {sampleDocs.Count}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Creating first document using CreateMemory API:\n",
      "   Document: company_handbook.txt\n",
      "   Content Type: text/plain\n",
      "   Method: Individual memory creation\n",
      "\n",
      "‚úÖ Created single memory: company_handbook.txt\n",
      "   Memory ID: a3c607d0-7ebd-4f63-9d34-5acda8822403\n",
      "   Content Type: text/plain\n",
      "   Status: PENDING\n",
      "\n",
      "üéØ Single memory creation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "// Create the first memory individually to demonstrate single memory creation\n",
    "async Task<Memory> CreateSingleMemory(string spaceId, DocumentInfo document)\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        MemoryCreationRequest memoryRequest;\n",
    "        \n",
    "        // Use appropriate content field based on binary flag\n",
    "        if (document.IsBinary)\n",
    "        {\n",
    "            memoryRequest = new MemoryCreationRequest(\n",
    "                spaceId: spaceId,\n",
    "                originalContentB64: document.ContentB64,  // Base64 for PDFs\n",
    "                contentType: document.ContentType,\n",
    "                chunkingConfig: DEMO_CHUNKING_CONFIG,\n",
    "                metadata: new Dictionary<string, string>\n",
    "                {\n",
    "                    [\"filename\"] = document.Filename,\n",
    "                    [\"source\"] = \"sample_documents\",\n",
    "                    [\"ingestion_method\"] = \"single\"\n",
    "                }\n",
    "            );\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            memoryRequest = new MemoryCreationRequest(\n",
    "                spaceId: spaceId,\n",
    "                originalContent: document.Content,         // Plain text\n",
    "                contentType: document.ContentType,\n",
    "                chunkingConfig: DEMO_CHUNKING_CONFIG,\n",
    "                metadata: new Dictionary<string, string>\n",
    "                {\n",
    "                    [\"filename\"] = document.Filename,\n",
    "                    [\"source\"] = \"sample_documents\",\n",
    "                    [\"ingestion_method\"] = \"single\"\n",
    "                }\n",
    "            );\n",
    "        }\n",
    "        \n",
    "        var memory = await memoriesApi.CreateMemoryAsync(memoryRequest);\n",
    "        \n",
    "        Console.WriteLine($\"‚úÖ Created single memory: {document.Filename}\");\n",
    "        Console.WriteLine($\"   Memory ID: {memory.MemoryId}\");\n",
    "        Console.WriteLine($\"   Content Type: {document.ContentType}\");\n",
    "        Console.WriteLine($\"   Status: {memory.ProcessingStatus}\");\n",
    "        Console.WriteLine();\n",
    "        \n",
    "        return memory;\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error creating memory for {document.Filename}: {e.Message}\");\n",
    "        return null;\n",
    "    }\n",
    "    catch (Exception e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Unexpected error with {document.Filename}: {e.Message}\");\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "\n",
    "Memory singleMemory = null;\n",
    "if (demoSpace != null && sampleDocs.Any())\n",
    "{\n",
    "    var firstDoc = sampleDocs[0];\n",
    "    Console.WriteLine(\"üìù Creating first document using CreateMemory API:\");\n",
    "    Console.WriteLine($\"   Document: {firstDoc.Filename}\");\n",
    "    Console.WriteLine($\"   Content Type: {firstDoc.ContentType}\");\n",
    "    Console.WriteLine(\"   Method: Individual memory creation\");\n",
    "    Console.WriteLine();\n",
    "    \n",
    "    singleMemory = await CreateSingleMemory(demoSpace.SpaceId, firstDoc);\n",
    "    \n",
    "    if (singleMemory != null)\n",
    "    {\n",
    "        Console.WriteLine(\"üéØ Single memory creation completed successfully!\");\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        Console.WriteLine(\"‚ö†Ô∏è  Single memory creation failed\");\n",
    "    }\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  Cannot create memory: missing space or documents\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Retrieving memory details using GetMemory API:\n",
      "   Memory ID: a3c607d0-7ebd-4f63-9d34-5acda8822403\n",
      "\n",
      "‚úÖ Successfully retrieved memory:\n",
      "   Memory ID: a3c607d0-7ebd-4f63-9d34-5acda8822403\n",
      "   Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "   Status: PENDING\n",
      "   Content Type: text/plain\n",
      "   Created At: 12/11/2025 12:48:39‚ÄØAM\n",
      "   Updated At: 12/11/2025 12:48:39‚ÄØAM\n",
      "\n",
      "   üìã Metadata:\n",
      "      source: sample_documents\n",
      "      filename: company_handbook.txt\n",
      "      ingestion_method: single\n",
      "\n",
      "üìñ Retrieving memory with content:\n",
      "‚úÖ Content retrieved and decoded:\n",
      "   Content length: 2342 characters\n",
      "   First 200 chars: ACME Corporation Employee Handbook\n",
      "\n",
      "Welcome to ACME Corporation! This handbook provides essential information about our company policies, procedures, and culture.\n",
      "\n",
      "COMPANY OVERVIEW\n",
      "ACME Corporation is...\n"
     ]
    }
   ],
   "source": [
    "// Demonstrate retrieving a memory by ID using GetMemory\n",
    "if (singleMemory != null)\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        Console.WriteLine(\"üìñ Retrieving memory details using GetMemory API:\");\n",
    "        Console.WriteLine($\"   Memory ID: {singleMemory.MemoryId}\");\n",
    "        Console.WriteLine();\n",
    "        \n",
    "        // Retrieve the memory without content\n",
    "        var retrievedMemory = await memoriesApi.GetMemoryAsync(singleMemory.MemoryId, false);\n",
    "        \n",
    "        Console.WriteLine(\"‚úÖ Successfully retrieved memory:\");\n",
    "        Console.WriteLine($\"   Memory ID: {retrievedMemory.MemoryId}\");\n",
    "        Console.WriteLine($\"   Space ID: {retrievedMemory.SpaceId}\");\n",
    "        Console.WriteLine($\"   Status: {retrievedMemory.ProcessingStatus}\");\n",
    "        Console.WriteLine($\"   Content Type: {retrievedMemory.ContentType}\");\n",
    "        Console.WriteLine($\"   Created At: {DateTimeOffset.FromUnixTimeMilliseconds(retrievedMemory.CreatedAt).DateTime}\");\n",
    "        Console.WriteLine($\"   Updated At: {DateTimeOffset.FromUnixTimeMilliseconds(retrievedMemory.UpdatedAt).DateTime}\");\n",
    "        \n",
    "        if (retrievedMemory.Metadata != null)\n",
    "        {\n",
    "            Console.WriteLine(\"\\n   üìã Metadata:\");\n",
    "            var metadataObj = retrievedMemory.Metadata as Newtonsoft.Json.Linq.JObject;\n",
    "            if (metadataObj != null)\n",
    "            {\n",
    "                foreach (var prop in metadataObj.Properties())\n",
    "                {\n",
    "                    Console.WriteLine($\"      {prop.Name}: {prop.Value}\");\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Now retrieve with content included\n",
    "        Console.WriteLine(\"\\nüìñ Retrieving memory with content:\");\n",
    "        var retrievedWithContent = await memoriesApi.GetMemoryAsync(singleMemory.MemoryId, true);\n",
    "        \n",
    "        if (retrievedWithContent.OriginalContent != null)\n",
    "        {\n",
    "            // Get the content as string (it may be FileParameter or string)\n",
    "            string base64Content = retrievedWithContent.OriginalContent.ToString();\n",
    "            \n",
    "            // Decode the base64 encoded content\n",
    "            var decodedBytes = Convert.FromBase64String(base64Content);\n",
    "            var decodedContent = System.Text.Encoding.UTF8.GetString(decodedBytes);\n",
    "            \n",
    "            Console.WriteLine(\"‚úÖ Content retrieved and decoded:\");\n",
    "            Console.WriteLine($\"   Content length: {decodedContent.Length} characters\");\n",
    "            var preview = decodedContent.Length > 200 ? decodedContent.Substring(0, 200) + \"...\" : decodedContent;\n",
    "            Console.WriteLine($\"   First 200 chars: {preview}\");\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            Console.WriteLine(\"‚ö†Ô∏è  No content available\");\n",
    "        }\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error retrieving memory: {e.Message}\");\n",
    "        Console.WriteLine($\"   Status code: {e.ErrorCode}\");\n",
    "    }\n",
    "    catch (Exception e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Unexpected error: {e.Message}\");\n",
    "    }\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  No memory available to retrieve\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Creating 4 memories using BatchCreateMemory API:\n",
      "‚úÖ Batch creation request submitted successfully\n",
      "\n",
      "üìã Total Memory Creation Summary:\n",
      "   üìÑ Single CreateMemory: 1 document\n",
      "   üì¶ Batch CreateMemory: 4 documents submitted\n",
      "   ‚è≥ Check processing status in the next cell\n"
     ]
    }
   ],
   "source": [
    "// Create the remaining documents using batch memory creation\n",
    "async Task CreateBatchMemories(string spaceId, List<DocumentInfo> documents)\n",
    "{\n",
    "    var memoryRequests = new List<MemoryCreationRequest>();\n",
    "    \n",
    "    foreach (var doc in documents)\n",
    "    {\n",
    "        MemoryCreationRequest memoryRequest;\n",
    "        \n",
    "        // Use appropriate content field based on binary flag\n",
    "        if (doc.IsBinary)\n",
    "        {\n",
    "            memoryRequest = new MemoryCreationRequest(\n",
    "                spaceId: spaceId,\n",
    "                originalContentB64: doc.ContentB64,  // Base64 for PDFs\n",
    "                contentType: doc.ContentType,\n",
    "                chunkingConfig: DEMO_CHUNKING_CONFIG,\n",
    "                metadata: new Dictionary<string, string>\n",
    "                {\n",
    "                    [\"filename\"] = doc.Filename,\n",
    "                    [\"source\"] = \"sample_documents\",\n",
    "                    [\"ingestion_method\"] = \"batch\"\n",
    "                }\n",
    "            );\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            memoryRequest = new MemoryCreationRequest(\n",
    "                spaceId: spaceId,\n",
    "                originalContent: doc.Content,         // Plain text\n",
    "                contentType: doc.ContentType,\n",
    "                chunkingConfig: DEMO_CHUNKING_CONFIG,\n",
    "                metadata: new Dictionary<string, string>\n",
    "                {\n",
    "                    [\"filename\"] = doc.Filename,\n",
    "                    [\"source\"] = \"sample_documents\",\n",
    "                    [\"ingestion_method\"] = \"batch\"\n",
    "                }\n",
    "            );\n",
    "        }\n",
    "        \n",
    "        memoryRequests.Add(memoryRequest);\n",
    "    }\n",
    "    \n",
    "    try\n",
    "    {\n",
    "        var batchRequest = new BatchMemoryCreationRequest(\n",
    "            requests: memoryRequests\n",
    "        );\n",
    "        \n",
    "        Console.WriteLine($\"üì¶ Creating {memoryRequests.Count} memories using BatchCreateMemory API:\");\n",
    "        \n",
    "        await memoriesApi.BatchCreateMemoryAsync(batchRequest);\n",
    "        \n",
    "        Console.WriteLine(\"‚úÖ Batch creation request submitted successfully\");\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error during batch creation: {e.Message}\");\n",
    "        Console.WriteLine($\"   Response code: {e.ErrorCode}\");\n",
    "    }\n",
    "    catch (Exception e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Unexpected error during batch creation: {e.Message}\");\n",
    "    }\n",
    "}\n",
    "\n",
    "if (demoSpace != null && sampleDocs.Count > 1)\n",
    "{\n",
    "    var remainingDocs = sampleDocs.Skip(1).ToList();\n",
    "    await CreateBatchMemories(demoSpace.SpaceId, remainingDocs);\n",
    "    \n",
    "    Console.WriteLine(\"\\nüìã Total Memory Creation Summary:\");\n",
    "    Console.WriteLine(\"   üìÑ Single CreateMemory: 1 document\");\n",
    "    Console.WriteLine($\"   üì¶ Batch CreateMemory: {remainingDocs.Count} documents submitted\");\n",
    "    Console.WriteLine(\"   ‚è≥ Check processing status in the next cell\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  Cannot create batch memories: insufficient documents or missing space\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Memories in space 'RAG Demo Knowledge Base (C#)':\n",
      "   Total memories: 5\n",
      "\n",
      "   1. security_policy.txt\n",
      "      Status: PENDING\n",
      "      Source: sample_documents\n",
      "      Ingestion Method: batch\n",
      "      Created: 12/11/2025 12:48:41‚ÄØAM\n",
      "\n",
      "   2. technical_documentation.txt\n",
      "      Status: PENDING\n",
      "      Source: sample_documents\n",
      "      Ingestion Method: batch\n",
      "      Created: 12/11/2025 12:48:41‚ÄØAM\n",
      "\n",
      "   3. product_faq.txt\n",
      "      Status: PENDING\n",
      "      Source: sample_documents\n",
      "      Ingestion Method: batch\n",
      "      Created: 12/11/2025 12:48:41‚ÄØAM\n",
      "\n",
      "   4. employee_handbook.pdf\n",
      "      Status: PENDING\n",
      "      Source: sample_documents\n",
      "      Ingestion Method: batch\n",
      "      Created: 12/11/2025 12:48:41‚ÄØAM\n",
      "\n",
      "   5. company_handbook.txt\n",
      "      Status: PENDING\n",
      "      Source: sample_documents\n",
      "      Ingestion Method: single\n",
      "      Created: 12/11/2025 12:48:39‚ÄØAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// List all memories in our space to verify they're ready\n",
    "if (demoSpace != null)\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        var memoriesResponse = await memoriesApi.ListMemoriesAsync(demoSpace.SpaceId);\n",
    "        var memories = memoriesResponse.Memories ?? new List<Memory>();\n",
    "        \n",
    "        Console.WriteLine($\"üìö Memories in space '{demoSpace.Name}':\");\n",
    "        Console.WriteLine($\"   Total memories: {memories.Count}\");\n",
    "        Console.WriteLine();\n",
    "        \n",
    "        for (int i = 0; i < memories.Count; i++)\n",
    "        {\n",
    "            var memory = memories[i];\n",
    "            \n",
    "            // Extract metadata using JObject\n",
    "            var metadataObj = memory.Metadata as Newtonsoft.Json.Linq.JObject;\n",
    "            var filename = \"Unknown\";\n",
    "            var source = \"Unknown\";\n",
    "            var ingestionMethod = \"Unknown\";\n",
    "            \n",
    "            if (metadataObj != null)\n",
    "            {\n",
    "                filename = metadataObj[\"filename\"]?.ToString() ?? \"Unknown\";\n",
    "                source = metadataObj[\"source\"]?.ToString() ?? \"Unknown\";\n",
    "                ingestionMethod = metadataObj[\"ingestion_method\"]?.ToString() ?? \"Unknown\";\n",
    "            }\n",
    "            \n",
    "            Console.WriteLine($\"   {i + 1}. {filename}\");\n",
    "            Console.WriteLine($\"      Status: {memory.ProcessingStatus}\");\n",
    "            Console.WriteLine($\"      Source: {source}\");\n",
    "            Console.WriteLine($\"      Ingestion Method: {ingestionMethod}\");\n",
    "            Console.WriteLine($\"      Created: {DateTimeOffset.FromUnixTimeMilliseconds(memory.CreatedAt).DateTime}\");\n",
    "            Console.WriteLine();\n",
    "        }\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error listing memories: {e.Message}\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Waiting for document processing to complete...\n",
      "   üí° Note: Batch memories are processed asynchronously, so we check by listing all memories in the space\n",
      "\n",
      "üìä Processing status: {PENDING: 4, COMPLETED: 1} (Total: 5 memories)\n",
      "üìä Processing status: {COMPLETED: 5} (Total: 5 memories)\n",
      "‚úÖ All documents processed successfully!\n",
      "üéâ Ready for semantic search and retrieval!\n",
      "üìà Batch API benefit: Multiple documents submitted in a single API call\n",
      "üîß Consistent chunking: All memories use DEMO_CHUNKING_CONFIG\n"
     ]
    }
   ],
   "source": [
    "// Monitor processing status for all created memories\n",
    "async Task<bool> WaitForProcessingCompletion(string spaceId, int maxWaitSeconds = 120)\n",
    "{\n",
    "    Console.WriteLine(\"‚è≥ Waiting for document processing to complete...\");\n",
    "    Console.WriteLine(\"   üí° Note: Batch memories are processed asynchronously, so we check by listing all memories in the space\");\n",
    "    Console.WriteLine();\n",
    "    \n",
    "    var startTime = DateTime.Now;\n",
    "    var maxWait = TimeSpan.FromSeconds(maxWaitSeconds);\n",
    "    \n",
    "    while (DateTime.Now - startTime < maxWait)\n",
    "    {\n",
    "        try\n",
    "        {\n",
    "            var memoriesResponse = await memoriesApi.ListMemoriesAsync(spaceId);\n",
    "            var memories = memoriesResponse.Memories ?? new List<Memory>();\n",
    "            \n",
    "            // Check processing status\n",
    "            var statusCounts = memories\n",
    "                .GroupBy(m => m.ProcessingStatus)\n",
    "                .ToDictionary(g => g.Key, g => g.Count());\n",
    "            \n",
    "            var statusStr = string.Join(\", \", statusCounts.Select(kv => $\"{kv.Key}: {kv.Value}\"));\n",
    "            Console.WriteLine($\"üìä Processing status: {{{statusStr}}} (Total: {memories.Count} memories)\");\n",
    "            \n",
    "            // Check if all are completed\n",
    "            if (memories.All(m => m.ProcessingStatus == \"COMPLETED\"))\n",
    "            {\n",
    "                Console.WriteLine(\"‚úÖ All documents processed successfully!\");\n",
    "                return true;\n",
    "            }\n",
    "            \n",
    "            // Check for any failures\n",
    "            var failedCount = memories.Count(m => m.ProcessingStatus == \"FAILED\");\n",
    "            if (failedCount > 0)\n",
    "            {\n",
    "                Console.WriteLine($\"‚ùå {failedCount} memories failed processing\");\n",
    "                return false;\n",
    "            }\n",
    "            \n",
    "            await Task.Delay(5000); // Wait 5 seconds\n",
    "        }\n",
    "        catch (ApiException e)\n",
    "        {\n",
    "            Console.WriteLine($\"‚ùå Error checking processing status: {e.Message}\");\n",
    "            return false;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Console.WriteLine($\"‚è∞ Timeout waiting for processing (waited {maxWaitSeconds}s)\");\n",
    "    return false;\n",
    "}\n",
    "\n",
    "if (demoSpace != null)\n",
    "{\n",
    "    var processingComplete = await WaitForProcessingCompletion(demoSpace.SpaceId);\n",
    "    \n",
    "    if (processingComplete)\n",
    "    {\n",
    "        Console.WriteLine(\"üéâ Ready for semantic search and retrieval!\");\n",
    "        Console.WriteLine(\"üìà Batch API benefit: Multiple documents submitted in a single API call\");\n",
    "        Console.WriteLine(\"üîß Consistent chunking: All memories use DEMO_CHUNKING_CONFIG\");\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        Console.WriteLine(\"‚ö†Ô∏è  Some documents may still be processing. You can continue with the tutorial.\");\n",
    "    }\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  Skipping processing check - no space available\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "search-header",
    "description": "Semantic search concepts and explanation",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Semantic Search & Retrieval\n",
    "\n",
    "### Why Semantic Search?\n",
    "\n",
    "**Traditional keyword search**:\n",
    "- Matches exact words or simple variations\n",
    "- Misses conceptually similar content with different wording\n",
    "- Example: \"vacation days\" won't match \"time off policy\"\n",
    "\n",
    "**Semantic search**:\n",
    "- Understands meaning and context\n",
    "- Finds conceptually similar content regardless of exact wording\n",
    "- Example: \"vacation days\" successfully matches \"time off policy\"\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Query: \"vacation policy\" \n",
    "   ‚Üì (embed with same embedder)\n",
    "Query Vector: [0.23, -0.45, ...]\n",
    "   ‚Üì (compare to all chunk vectors)\n",
    "Most Similar Chunks: (by cosine similarity)\n",
    "   1. \"TIME OFF POLICY...\" (score: -0.604)\n",
    "   2. \"Vacation requests...\" (score: -0.544)\n",
    "   3. \"WORK HOURS...\" (score: -0.458)\n",
    "```\n",
    "\n",
    "### Understanding Relevance Scores\n",
    "\n",
    "GoodMem uses **cosine distance** (negative cosine similarity):\n",
    "- **Lower values = more relevant** (e.g., -0.6 is better than -0.4)\n",
    "- **Range**: Typically -1.0 (most similar) to 0.0 (unrelated)\n",
    "- **Good threshold**: Results under -0.3 are usually relevant\n",
    "- **Context matters**: Exact scores vary by embedder and content\n",
    "\n",
    "### Streaming API Benefits\n",
    "\n",
    "GoodMem's streaming API:\n",
    "- **Real-time results**: Process chunks as they arrive\n",
    "- **Low latency**: Start showing results immediately\n",
    "- **Memory efficient**: No need to buffer entire result set\n",
    "- **Progressive UI**: Update interface as more results come in\n",
    "\n",
    "### What We'll Do\n",
    "\n",
    "1. Implement a semantic search function using GoodMem's streaming API\n",
    "2. Process different event types (chunks, memories, metadata)\n",
    "3. Display results with relevance scores\n",
    "4. Test with various queries to see semantic matching in action\n",
    "\n",
    "Now comes the exciting part! Let's perform semantic search using GoodMem's streaming API. This will:\n",
    "\n",
    "- **Find relevant chunks** based on semantic similarity\n",
    "- **Stream results** in real-time\n",
    "- **Include relevance scores** for ranking\n",
    "- **Return structured data** for easy processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Streaming search for: 'What is the vacation policy for employees?'\n",
      "üìÅ Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "üìä Max results: 5\n",
      "--------------------------------------------------\n",
      "üîÑ BEGIN: retrieve\n",
      "\n",
      "1. Relevance: -0.679\n",
      "   TIME OFF POLICY\n",
      "All full-time employees receive:\n",
      "- 15 days of paid vacation annually (increases to 2...\n",
      "\n",
      "2. Relevance: -0.674\n",
      "   1.  Eligibility \n",
      "\n",
      " \n",
      "All regular full-time employees are eligible for vacation benefits. \n",
      "\n",
      " \n",
      "2.  Accr...\n",
      "\n",
      "3. Relevance: -0.662\n",
      "   [ORGANIZATION] has established the following vacation plan to provide eligible employees \n",
      "time off w...\n",
      "\n",
      "4. Relevance: -0.646\n",
      "   Vacation Pay: Vacation pay shall be based on the employee‚Äôs regular base rate and \n",
      "working schedule,...\n",
      "\n",
      "5. Relevance: -0.643\n",
      "   employees can use paid vacation time in minimum increments of one day.xii \n",
      "\n",
      " \n",
      "Accumulating Vacation:...\n",
      "üîÑ END: \n",
      "‚úÖ Streaming search completed: 5 chunks found, 10 events processed\n"
     ]
    }
   ],
   "source": [
    "// Helper class to hold search results\n",
    "public class SearchResult\n",
    "{\n",
    "    public string ChunkText { get; set; }\n",
    "    public double RelevanceScore { get; set; }\n",
    "    public int MemoryIndex { get; set; }\n",
    "    public string ResultSetId { get; set; }\n",
    "    public int ChunkSequence { get; set; }\n",
    "}\n",
    "\n",
    "// Perform semantic search using GoodMem's streaming API\n",
    "async Task<List<SearchResult>> SemanticSearchStreaming(string query, string spaceId, int maxResults = 5)\n",
    "{\n",
    "    Console.WriteLine($\"üîç Streaming search for: '{query}'\");\n",
    "    Console.WriteLine($\"üìÅ Space ID: {spaceId}\");\n",
    "    Console.WriteLine($\"üìä Max results: {maxResults}\");\n",
    "    Console.WriteLine(new string('-', 50));\n",
    "    \n",
    "    try\n",
    "    {\n",
    "        var streamingClient = new Pairsystems.Goodmem.Client.StreamingClient(config);\n",
    "        var request = new MemoryStreamRequest\n",
    "        {\n",
    "            Message = query,\n",
    "            SpaceIds = new List<string> { spaceId },\n",
    "            RequestedSize = maxResults,\n",
    "            FetchMemory = true,\n",
    "            FetchMemoryContent = false,\n",
    "            Format = \"ndjson\"\n",
    "        };\n",
    "\n",
    "        var retrievedChunks = new List<SearchResult>();\n",
    "        var eventCount = 0;\n",
    "        \n",
    "        var cancellationTokenSource = new CancellationTokenSource(TimeSpan.FromSeconds(30));\n",
    "        \n",
    "        await foreach (var streamingEvent in streamingClient.RetrieveMemoryStreamAsync(request, cancellationTokenSource.Token))\n",
    "        {\n",
    "            eventCount++;\n",
    "\n",
    "            if (streamingEvent.RetrievedItem?.Chunk != null)\n",
    "            {\n",
    "                var chunkRef = streamingEvent.RetrievedItem.Chunk;\n",
    "                var chunkData = chunkRef.Chunk;\n",
    "                \n",
    "                var chunkText = chunkData.ContainsKey(\"chunkText\") ? chunkData[\"chunkText\"]?.ToString() : \"\";\n",
    "                var chunkSequence = ((System.Text.Json.JsonElement)chunkData[\"chunkSequenceNumber\"]).GetInt32();\n",
    "\n",
    "                retrievedChunks.Add(new SearchResult\n",
    "                {\n",
    "                    ChunkText = chunkText,\n",
    "                    RelevanceScore = chunkRef.RelevanceScore,\n",
    "                    MemoryIndex = chunkRef.MemoryIndex,\n",
    "                    ResultSetId = chunkRef.ResultSetId,\n",
    "                    ChunkSequence = chunkSequence\n",
    "                });\n",
    "\n",
    "                Console.WriteLine($\"\\n{retrievedChunks.Count}. Relevance: {chunkRef.RelevanceScore:F3}\");\n",
    "                var preview = chunkText.Length > 100 ? chunkText.Substring(0, 100) + \"...\" : chunkText;\n",
    "                Console.WriteLine($\"   {preview}\");\n",
    "\n",
    "            }\n",
    "            else if (streamingEvent.ResultSetBoundary != null)\n",
    "            {\n",
    "                Console.WriteLine($\"üîÑ {streamingEvent.ResultSetBoundary.Kind}: {streamingEvent.ResultSetBoundary.StageName}\");\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        Console.WriteLine($\"‚úÖ Streaming search completed: {retrievedChunks.Count} chunks found, {eventCount} events processed\");\n",
    "        return retrievedChunks;\n",
    "    }\n",
    "    catch (Pairsystems.Goodmem.Client.StreamingException ex)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Streaming error: {ex.Message}\");\n",
    "        return new List<SearchResult>();\n",
    "    }\n",
    "    catch (Exception ex)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Unexpected error: {ex.Message}\");\n",
    "        return new List<SearchResult>();\n",
    "    }\n",
    "}\n",
    "\n",
    "// Test semantic search with a sample query\n",
    "if (demoSpace != null)\n",
    "{\n",
    "    var sampleQuery = \"What is the vacation policy for employees?\";\n",
    "    var searchResults = await SemanticSearchStreaming(sampleQuery, demoSpace.SpaceId);\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  No space available for search\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Test Query 1: How do I reset my password?\n",
      "============================================================\n",
      "üîç Streaming search for: 'How do I reset my password?'\n",
      "üìÅ Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "üìä Max results: 3\n",
      "--------------------------------------------------\n",
      "üîÑ BEGIN: retrieve\n",
      "\n",
      "1. Relevance: -0.370\n",
      "   password they use to gain access to computers or the Internet, as well as any change to \n",
      "such passwo...\n",
      "\n",
      "2. Relevance: -0.363\n",
      "   - No reuse of last 12 passwords\n",
      "- Must be changed every 90 days for privileged accounts\n",
      "- Multi-fact...\n",
      "\n",
      "3. Relevance: -0.306\n",
      "   Each classification level has specific handling, storage, and transmission requirements outlined in ...\n",
      "üîÑ END: \n",
      "‚úÖ Streaming search completed: 3 chunks found, 8 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Test Query 2: What are the security requirements for remote work?\n",
      "============================================================\n",
      "üîç Streaming search for: 'What are the security requirements for remote work?'\n",
      "üìÅ Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "üìä Max results: 3\n",
      "--------------------------------------------------\n",
      "üîÑ BEGIN: retrieve\n",
      "\n",
      "1. Relevance: -0.710\n",
      "   - Report suspicious emails or security incidents immediately\n",
      "\n",
      "REMOTE WORK SECURITY\n",
      "Remote employees ...\n",
      "\n",
      "2. Relevance: -0.530\n",
      "   - Keep work devices physically secure and locked when unattended\n",
      "- Use only approved cloud storage s...\n",
      "\n",
      "3. Relevance: -0.471\n",
      "   SECURITY TRAINING\n",
      "All employees must complete:\n",
      "- Security awareness training within 30 days of hire\n",
      "...\n",
      "üîÑ END: \n",
      "‚úÖ Streaming search completed: 3 chunks found, 7 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Test Query 3: API authentication and rate limits\n",
      "============================================================\n",
      "üîç Streaming search for: 'API authentication and rate limits'\n",
      "üìÅ Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "üìä Max results: 3\n",
      "--------------------------------------------------\n",
      "üîÑ BEGIN: retrieve\n",
      "\n",
      "1. Relevance: -0.554\n",
      "   BASE URL\n",
      "All API endpoints are accessed via:\n",
      "https://api.acme.com/v1/\n",
      "\n",
      "RATE LIMITING\n",
      "API requests ar...\n",
      "\n",
      "2. Relevance: -0.462\n",
      "   - 403: Forbidden - Insufficient permissions\n",
      "- 404: Not Found - Resource does not exist\n",
      "- 429: Too Ma...\n",
      "\n",
      "3. Relevance: -0.458\n",
      "   AUTHENTICATION\n",
      "All API requests require authentication using API keys. Include your API key in the r...\n",
      "üîÑ END: \n",
      "‚úÖ Streaming search completed: 3 chunks found, 7 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Test Query 4: Employee benefits and health insurance\n",
      "============================================================\n",
      "üîç Streaming search for: 'Employee benefits and health insurance'\n",
      "üìÅ Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "üìä Max results: 3\n",
      "--------------------------------------------------\n",
      "üîÑ BEGIN: retrieve\n",
      "\n",
      "1. Relevance: -0.600\n",
      "   - Health insurance with 90% premium coverage\n",
      "- Dental and vision insurance\n",
      "- 401(k) retirement plan ...\n",
      "\n",
      "2. Relevance: -0.590\n",
      "   A. Employee Benefits...................................................................................\n",
      "\n",
      "3. Relevance: -0.586\n",
      "   [ORGANIZATION]. \n",
      "\n",
      " \n",
      "F. Health Insurance \n",
      "\n",
      " \n",
      "\n",
      "All employees classified by [ORGANIZATION] as regularly...\n",
      "üîÑ END: \n",
      "‚úÖ Streaming search completed: 3 chunks found, 8 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Test Query 5: How much does the software cost?\n",
      "============================================================\n",
      "üîç Streaming search for: 'How much does the software cost?'\n",
      "üìÅ Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "üìä Max results: 3\n",
      "--------------------------------------------------\n",
      "üîÑ BEGIN: retrieve\n",
      "\n",
      "1. Relevance: -0.496\n",
      "   A: The ACME Software Suite is an integrated platform that provides business management tools includi...\n",
      "\n",
      "2. Relevance: -0.471\n",
      "   A: We offer three pricing tiers:\n",
      "- Starter: $29/month for up to 5 users\n",
      "- Professional: $79/month fo...\n",
      "\n",
      "3. Relevance: -0.425\n",
      "   Q: Is there a free trial available?\n",
      "A: Yes, we offer a 14-day free trial with full access to all Pro...\n",
      "üîÑ END: \n",
      "‚úÖ Streaming search completed: 3 chunks found, 7 events processed\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úÖ All queries completed\n"
     ]
    }
   ],
   "source": [
    "// Let's try a few different queries to see how streaming semantic search works\n",
    "async Task TestMultipleStreamingQueries(string spaceId)\n",
    "{\n",
    "    var testQueries = new List<string>\n",
    "    {\n",
    "        \"How do I reset my password?\",\n",
    "        \"What are the security requirements for remote work?\",\n",
    "        \"API authentication and rate limits\",\n",
    "        \"Employee benefits and health insurance\",\n",
    "        \"How much does the software cost?\"\n",
    "    };\n",
    "    \n",
    "    for (int i = 0; i < testQueries.Count; i++)\n",
    "    {\n",
    "        var query = testQueries[i];\n",
    "        Console.WriteLine($\"\\nüîç Test Query {i + 1}: {query}\");\n",
    "        Console.WriteLine(new string('=', 60));\n",
    "        \n",
    "        await SemanticSearchStreaming(query, spaceId, 3);\n",
    "        \n",
    "        Console.WriteLine(\"\\n\" + new string('-', 60));\n",
    "    }\n",
    "}\n",
    "\n",
    "if (demoSpace != null)\n",
    "{\n",
    "    await TestMultipleStreamingQueries(demoSpace.SpaceId);\n",
    "    Console.WriteLine(\"\\n‚úÖ All queries completed\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  No space available for testing multiple streaming queries\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "advanced-header",
    "description": "Advanced features section header",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Advanced Features\n",
    "\n",
    "Congratulations! üéâ You've successfully built a semantic search system using GoodMem. Here's what you've accomplished:\n",
    "\n",
    "### ‚úÖ What You Built\n",
    "- **Document ingestion pipeline** with automatic chunking and embedding\n",
    "- **Semantic search system** with relevance scoring\n",
    "- **Simple Q&A system** using GoodMem's vector capabilities\n",
    "\n",
    "### üöÄ Next Steps for Advanced Implementation\n",
    "\n",
    "#### Reranking\n",
    "Improve search quality by adding a reranking stage. **Rerankers** are specialized models that re-score search results to improve relevance:\n",
    "\n",
    "- **Two-stage retrieval**: Fast initial retrieval with embeddings, then precise reranking\n",
    "- **Better relevance**: Rerankers use cross-attention to understand query-document relationships\n",
    "- **Reduced costs**: Rerank only top-K results instead of entire corpus\n",
    "- **Voyage AI reranker**: Industry-leading reranking model with state-of-the-art performance\n",
    "\n",
    "The combination of fast embedding-based retrieval followed by accurate reranking provides the best balance of speed and quality for production RAG systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "reranker-header",
    "description": "Reranker explanation and concepts",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Configuring a Reranker\n",
    "\n",
    "To further improve search quality, we can add a **reranker** to our RAG pipeline. While embedders provide fast semantic search, rerankers use more sophisticated models to re-score the top results for better accuracy.\n",
    "\n",
    "### Why Use Reranking?\n",
    "\n",
    "1. **Higher Accuracy**: Rerankers use cross-encoder architectures that directly compare queries and documents\n",
    "2. **Two-Stage Pipeline**: Fast retrieval with embeddings + precise reranking = optimal performance\n",
    "3. **Cost Effective**: Only rerank top-K results (e.g., top 20) rather than entire corpus\n",
    "\n",
    "### Voyage AI Reranker\n",
    "\n",
    "We'll use Voyage AI's `rerank-2.5` model, which provides:\n",
    "- **State-of-the-art performance** on reranking benchmarks\n",
    "- **Fast inference** optimized for production use\n",
    "- **Simple API** that integrates seamlessly with GoodMem\n",
    "\n",
    "**Note**: You'll need a Voyage AI API key set in your environment variable `VOYAGE_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating new Voyage reranker...\n",
      "‚úÖ Successfully created Voyage reranker!\n",
      "   Display Name: Voyage Rerank 2.5\n",
      "   Reranker ID: 55eaa698-23d8-4e97-9b3f-59960cb11e87\n",
      "   Provider: VOYAGE\n",
      "   Model: rerank-2.5\n",
      "\n",
      "üíæ Stored for reuse:\n",
      "   Variable: voyageReranker\n",
      "   Reranker ID: 55eaa698-23d8-4e97-9b3f-59960cb11e87\n"
     ]
    }
   ],
   "source": [
    "// Create or retrieve Voyage AI reranker and store for reuse\n",
    "RerankerResponse voyageReranker = null;\n",
    "\n",
    "var voyageApiKey = Environment.GetEnvironmentVariable(\"VOYAGE_API_KEY\") ?? \"\";\n",
    "\n",
    "if (string.IsNullOrEmpty(voyageApiKey))\n",
    "{\n",
    "    Console.WriteLine(\"‚ùå VOYAGE_API_KEY environment variable not set!\");\n",
    "    Console.WriteLine(\"   Please set your Voyage AI API key:\");\n",
    "    Console.WriteLine(\"   export VOYAGE_API_KEY='your-api-key-here'\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        // Initialize RerankersApi\n",
    "        var rerankersApi = new RerankersApi(config);\n",
    "\n",
    "        // Check if reranker already exists\n",
    "        var rerankersResponse = await rerankersApi.ListRerankersAsync();\n",
    "        var existingRerankers = rerankersResponse.Rerankers?.ToList() ?? new List<RerankerResponse>();\n",
    "\n",
    "        var existingReranker = existingRerankers.FirstOrDefault(r =>\n",
    "            r.ProviderType.ToString() == \"VOYAGE\" &&\n",
    "            r.ModelIdentifier == \"rerank-2.5\");\n",
    "\n",
    "        if (existingReranker != null)\n",
    "        {\n",
    "            voyageReranker = existingReranker;  // Store existing reranker\n",
    "            Console.WriteLine(\"‚úÖ Voyage reranker already exists!\");\n",
    "            Console.WriteLine($\"   Display Name: {voyageReranker.DisplayName}\");\n",
    "            Console.WriteLine($\"   Reranker ID: {voyageReranker.RerankerId}\");\n",
    "            Console.WriteLine($\"   Model: {voyageReranker.ModelIdentifier}\");\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            Console.WriteLine(\"üîß Creating new Voyage reranker...\");\n",
    "\n",
    "            // Create API key authentication\n",
    "            var apiKeyAuth = new ApiKeyAuth\n",
    "            {\n",
    "                InlineSecret = voyageApiKey,\n",
    "                HeaderName = \"Authorization\",\n",
    "                Prefix = \"Bearer \"\n",
    "            };\n",
    "\n",
    "            var credentials = new EndpointAuthentication\n",
    "            {\n",
    "                Kind = CredentialKind.CREDENTIALKINDAPIKEY,\n",
    "                ApiKey = apiKeyAuth\n",
    "            };\n",
    "\n",
    "            // Create reranker request\n",
    "            var rerankerRequest = new RerankerCreationRequest(\n",
    "                displayName: \"Voyage Rerank 2.5\",\n",
    "                providerType: ProviderType.VOYAGE,\n",
    "                endpointUrl: \"https://api.voyageai.com\",\n",
    "                modelIdentifier: \"rerank-2.5\",\n",
    "                apiPath: \"/v1/rerank\",\n",
    "                credentials: credentials,\n",
    "                description: \"Voyage AI reranker for improving search result relevance\"\n",
    "            );\n",
    "\n",
    "            var newReranker = await rerankersApi.CreateRerankerAsync(rerankerRequest);\n",
    "            voyageReranker = newReranker;  // Store new reranker\n",
    "\n",
    "            Console.WriteLine(\"‚úÖ Successfully created Voyage reranker!\");\n",
    "            Console.WriteLine($\"   Display Name: {voyageReranker.DisplayName}\");\n",
    "            Console.WriteLine($\"   Reranker ID: {voyageReranker.RerankerId}\");\n",
    "            Console.WriteLine($\"   Provider: {voyageReranker.ProviderType}\");\n",
    "            Console.WriteLine($\"   Model: {voyageReranker.ModelIdentifier}\");\n",
    "        }\n",
    "        \n",
    "        // Print stored variable info\n",
    "        if (voyageReranker != null)\n",
    "        {\n",
    "            Console.WriteLine(\"\\nüíæ Stored for reuse:\");\n",
    "            Console.WriteLine(\"   Variable: voyageReranker\");\n",
    "            Console.WriteLine($\"   Reranker ID: {voyageReranker.RerankerId}\");\n",
    "        }\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error creating reranker: {e.Message}\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "llm-header",
    "description": "LLM explanation and role in RAG",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Registering an LLM\n",
    "\n",
    "The final component in our RAG pipeline is the **LLM (Large Language Model)** - the generation component that creates natural language responses using the retrieved and reranked context.\n",
    "\n",
    "### Role of LLMs in RAG\n",
    "\n",
    "After retrieving and reranking relevant chunks, the LLM:\n",
    "1. **Receives the query** and retrieved context\n",
    "2. **Generates a response** that synthesizes information from multiple sources\n",
    "3. **Maintains coherence** while staying grounded in the retrieved facts\n",
    "\n",
    "### OpenAI GPT-4o-mini\n",
    "\n",
    "We'll use OpenAI's `gpt-4o-mini` model, which provides:\n",
    "- **Fast inference** with low latency for real-time applications\n",
    "- **Cost-effective** pricing compared to larger models\n",
    "- **High quality** responses suitable for most RAG use cases\n",
    "- **Function calling** support for advanced workflows\n",
    "\n",
    "**Note**: This uses the same `OPENAI_API_KEY` environment variable as the embedder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Registering new OpenAI GPT-4o-mini LLM...\n",
      "‚úÖ Successfully registered OpenAI GPT-4o-mini LLM!\n",
      "   Display Name: OpenAI GPT-4o Mini\n",
      "   LLM ID: 3222528f-9cd8-47c8-bd73-9d1cbdaa83f6\n",
      "   Provider: OPENAI\n",
      "   Model: gpt-4o-mini\n",
      "\n",
      "üíæ Stored for reuse:\n",
      "   Variable: openaiLlm\n",
      "   LLM ID: 3222528f-9cd8-47c8-bd73-9d1cbdaa83f6\n"
     ]
    }
   ],
   "source": [
    "// Register OpenAI GPT-4o-mini LLM and store for reuse\n",
    "LLMResponse openaiLlm = null;\n",
    "\n",
    "var openaiApiKey = Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\") ?? \"\";\n",
    "\n",
    "if (string.IsNullOrEmpty(openaiApiKey))\n",
    "{\n",
    "    Console.WriteLine(\"‚ùå OPENAI_API_KEY environment variable not set!\");\n",
    "    Console.WriteLine(\"   Please set your OpenAI API key:\");\n",
    "    Console.WriteLine(\"   export OPENAI_API_KEY='your-api-key-here'\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        // Initialize LLMsApi (note: LLMsApi, not LlmsApi)\n",
    "        var llmsApi = new LLMsApi(config);\n",
    "\n",
    "        // Check if LLM already exists\n",
    "        var llmsResponse = await llmsApi.ListLLMsAsync();\n",
    "        var existingLLMs = llmsResponse.Llms?.ToList() ?? new List<LLMResponse>();\n",
    "\n",
    "        var existingLLM = existingLLMs.FirstOrDefault(llm =>\n",
    "            llm.ProviderType.ToString() == \"OPENAI\" &&\n",
    "            llm.ModelIdentifier == \"gpt-4o-mini\");\n",
    "\n",
    "        if (existingLLM != null)\n",
    "        {\n",
    "            openaiLlm = existingLLM;  // Store existing LLM\n",
    "            Console.WriteLine(\"‚úÖ OpenAI GPT-4o-mini LLM already exists!\");\n",
    "            Console.WriteLine($\"   Display Name: {openaiLlm.DisplayName}\");\n",
    "            Console.WriteLine($\"   LLM ID: {openaiLlm.LlmId}\");\n",
    "            Console.WriteLine($\"   Model: {openaiLlm.ModelIdentifier}\");\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            Console.WriteLine(\"üîß Registering new OpenAI GPT-4o-mini LLM...\");\n",
    "\n",
    "            // Create API key authentication\n",
    "            var apiKeyAuth = new ApiKeyAuth\n",
    "            {\n",
    "                InlineSecret = openaiApiKey,\n",
    "                HeaderName = \"Authorization\",\n",
    "                Prefix = \"Bearer \"\n",
    "            };\n",
    "\n",
    "            var credentials = new EndpointAuthentication\n",
    "            {\n",
    "                Kind = CredentialKind.CREDENTIALKINDAPIKEY,\n",
    "                ApiKey = apiKeyAuth\n",
    "            };\n",
    "\n",
    "            // Define LLM capabilities\n",
    "            var capabilities = new LLMCapabilities(\n",
    "                supportsChat: true,\n",
    "                supportsCompletion: false,\n",
    "                supportsFunctionCalling: true,\n",
    "                supportsSystemMessages: true,\n",
    "                supportsStreaming: true,\n",
    "                supportsSamplingParameters: true\n",
    "            );\n",
    "\n",
    "            // Create LLM request\n",
    "            var llmRequest = new LLMCreationRequest(\n",
    "                displayName: \"OpenAI GPT-4o Mini\",\n",
    "                providerType: LLMProviderType.OPENAI,\n",
    "                endpointUrl: \"https://api.openai.com/v1\",\n",
    "                modelIdentifier: \"gpt-4o-mini\",\n",
    "                apiPath: \"/chat/completions\",\n",
    "                credentials: credentials,\n",
    "                capabilities: capabilities,\n",
    "                description: \"OpenAI's GPT-4o Mini model for fast and efficient text generation\"\n",
    "            );\n",
    "\n",
    "            var response = await llmsApi.CreateLLMAsync(llmRequest);\n",
    "            var newLLM = response.Llm;\n",
    "            openaiLlm = newLLM;  // Store new LLM\n",
    "\n",
    "            Console.WriteLine(\"‚úÖ Successfully registered OpenAI GPT-4o-mini LLM!\");\n",
    "            Console.WriteLine($\"   Display Name: {openaiLlm.DisplayName}\");\n",
    "            Console.WriteLine($\"   LLM ID: {openaiLlm.LlmId}\");\n",
    "            Console.WriteLine($\"   Provider: {openaiLlm.ProviderType}\");\n",
    "            Console.WriteLine($\"   Model: {openaiLlm.ModelIdentifier}\");\n",
    "        }\n",
    "        \n",
    "        // Print stored variable info\n",
    "        if (openaiLlm != null)\n",
    "        {\n",
    "            Console.WriteLine(\"\\nüíæ Stored for reuse:\");\n",
    "            Console.WriteLine(\"   Variable: openaiLlm\");\n",
    "            Console.WriteLine($\"   LLM ID: {openaiLlm.LlmId}\");\n",
    "        }\n",
    "    }\n",
    "    catch (ApiException e)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error registering LLM: {e.Message}\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "rag-header",
    "description": "Enhanced RAG pipeline explanation",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## Enhanced RAG with Reranking and LLM Generation\n",
    "\n",
    "Now that we have all the components configured (embedder, reranker, and LLM), let's use the complete RAG pipeline! This demonstrates the full power of GoodMem:\n",
    "\n",
    "1. **Retrieval**: Fast semantic search finds relevant chunks\n",
    "2. **Reranking**: Voyage AI reranker re-scores results for better relevance  \n",
    "3. **Generation**: OpenAI GPT-4o-mini generates a coherent response using the reranked context\n",
    "\n",
    "This provides significantly better answer quality compared to simple retrieval alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Complete RAG Pipeline with Reranker + LLM\n",
      "\n",
      "üîç RAG Query: 'What is the vacation policy for employees?'\n",
      "üìÅ Space ID: 6a06e8c5-114a-48c5-8f71-f1426a23ce31\n",
      "üìä Max results: 3\n",
      "======================================================================\n",
      "   üìÑ Chunk 1:\n",
      "      Relevance: 0.863\n",
      "      Text: TIME OFF POLICY\n",
      "All full-time employees receive:\n",
      "- 15 days of paid vacation annually (increases to 20 days after 3 years)\n",
      "- 10 sick days per year\n",
      "- 8 ...\n",
      "\n",
      "   üìÑ Chunk 2:\n",
      "      Relevance: 0.824\n",
      "      Text: [ORGANIZATION] has established the following vacation plan to provide eligible employees \n",
      "time off with pay so that they may be free from their regula...\n",
      "\n",
      "   üìÑ Chunk 3:\n",
      "      Relevance: 0.770\n",
      "      Text: 1.  Eligibility \n",
      "\n",
      " \n",
      "All regular full-time employees are eligible for vacation benefits. \n",
      "\n",
      " \n",
      "2.  Accrual \n",
      "\n",
      " \n",
      "Eligible employees accrue vacation in acco...\n",
      "\n",
      "\n",
      "ü§ñ LLM Generated Response:\n",
      "   The vacation policy for employees at [ORGANIZATION] includes 15 days of paid vacation annually for full-time employees, which increases to 20 days after three years of service. Additionally, employees receive 10 sick days per year, 8 company holidays, and personal days as needed with manager approval. All regular full-time employees are eligible for these vacation benefits.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "‚úÖ RAG completed successfully\n",
      "   LLM response: ‚úì\n",
      "   Reranked chunks: 3\n",
      "\n",
      "üéâ RAG pipeline completed!\n",
      "   LLM Response: Available\n",
      "   Chunks Retrieved: 3\n"
     ]
    }
   ],
   "source": [
    "// Helper classes for RAG results\n",
    "public class RagChunk\n",
    "{\n",
    "    public string ChunkText { get; set; }\n",
    "    public double RelevanceScore { get; set; }\n",
    "\n",
    "    public RagChunk(string chunkText, double relevanceScore)\n",
    "    {\n",
    "        ChunkText = chunkText;\n",
    "        RelevanceScore = relevanceScore;\n",
    "    }\n",
    "}\n",
    "\n",
    "public class RagResult\n",
    "{\n",
    "    public string LlmResponse { get; set; }\n",
    "    public List<RagChunk> Chunks { get; set; }\n",
    "\n",
    "    public RagResult(string llmResponse, List<RagChunk> chunks)\n",
    "    {\n",
    "        LlmResponse = llmResponse;\n",
    "        Chunks = chunks;\n",
    "    }\n",
    "}\n",
    "\n",
    "// RAG pipeline function - wraps streaming with reranking and LLM generation\n",
    "async Task<RagResult> RagPipelineStreaming(string query, string spaceId, string rerankerId, string llmId, int maxResults)\n",
    "{\n",
    "    /**\n",
    "     * Perform semantic search with reranking and LLM generation.\n",
    "     *\n",
    "     * This demonstrates the complete RAG pipeline:\n",
    "     * 1. Retrieval - Find relevant chunks using semantic search\n",
    "     * 2. Reranking - Re-score results with reranker\n",
    "     * 3. Generation - Generate answer with LLM\n",
    "     *\n",
    "     * @param query The search query\n",
    "     * @param spaceId ID of the space to search\n",
    "     * @param rerankerId ID of the reranker to use\n",
    "     * @param llmId ID of the LLM for generation\n",
    "     * @param maxResults Maximum number of results\n",
    "     * @return RagResult containing LLM response and reranked chunks\n",
    "     */\n",
    "\n",
    "    Console.WriteLine($\"üîç RAG Query: '{query}'\");\n",
    "    Console.WriteLine($\"üìÅ Space ID: {spaceId}\");\n",
    "    Console.WriteLine($\"üìä Max results: {maxResults}\");\n",
    "    Console.WriteLine(new string('=', 70));\n",
    "\n",
    "    try\n",
    "    {\n",
    "        // Create streaming client\n",
    "        var streamingClient = new StreamingClient(config);\n",
    "\n",
    "        // Build post-processor configuration\n",
    "        var postProcessorConfig = new Dictionary<string, object>\n",
    "        {\n",
    "            [\"llm_id\"] = llmId,                     // Use passed ID\n",
    "            [\"reranker_id\"] = rerankerId,           // Use passed ID\n",
    "            [\"relevance_threshold\"] = 0.3,\n",
    "            [\"max_results\"] = maxResults\n",
    "        };\n",
    "\n",
    "        // Create memory stream request with post-processor\n",
    "        var request = new AdvancedMemoryStreamRequest\n",
    "        {\n",
    "            Message = query,\n",
    "            SpaceIds = new List<string> { spaceId },\n",
    "            RequestedSize = maxResults,\n",
    "            FetchMemory = true,\n",
    "            FetchMemoryContent = false,\n",
    "            PostProcessorName = \"com.goodmem.retrieval.postprocess.ChatPostProcessorFactory\",\n",
    "            PostProcessorConfig = postProcessorConfig,\n",
    "            Format = \"ndjson\"\n",
    "        };\n",
    "\n",
    "        string llmResponse = null;\n",
    "        var rerankedChunks = new List<RagChunk>();\n",
    "\n",
    "        var cancellationTokenSource = new CancellationTokenSource(TimeSpan.FromSeconds(60));\n",
    "\n",
    "        // Process streaming events\n",
    "        await foreach (var streamingEvent in streamingClient.RetrieveMemoryStreamAdvancedAsync(request, cancellationTokenSource.Token))\n",
    "        {\n",
    "            // Handle LLM-generated response\n",
    "            if (streamingEvent.AbstractReply != null && llmResponse == null)\n",
    "            {\n",
    "                llmResponse = streamingEvent.AbstractReply.Text;\n",
    "                Console.WriteLine(\"\\nü§ñ LLM Generated Response:\");\n",
    "                Console.WriteLine($\"   {llmResponse}\");\n",
    "                Console.WriteLine();\n",
    "                Console.WriteLine(new string('-', 70));\n",
    "            }\n",
    "\n",
    "            // Handle reranked chunks\n",
    "            if (streamingEvent.RetrievedItem?.Chunk != null)\n",
    "            {\n",
    "                var chunkRef = streamingEvent.RetrievedItem.Chunk;\n",
    "                var chunkData = chunkRef.Chunk;\n",
    "\n",
    "                var chunkText = chunkData.ContainsKey(\"chunkText\") ? chunkData[\"chunkText\"]?.ToString() : \"\";\n",
    "                var relevanceScore = chunkRef.RelevanceScore;\n",
    "                rerankedChunks.Add(new RagChunk(chunkText, relevanceScore));\n",
    "\n",
    "                Console.WriteLine($\"   üìÑ Chunk {rerankedChunks.Count}:\");\n",
    "                Console.WriteLine($\"      Relevance: {relevanceScore:F3}\");\n",
    "                var preview = chunkText.Length > 150 ? chunkText.Substring(0, 150) + \"...\" : chunkText;\n",
    "                Console.WriteLine($\"      Text: {preview}\");\n",
    "                Console.WriteLine();\n",
    "            }\n",
    "        }\n",
    "\n",
    "        Console.WriteLine(new string('=', 70));\n",
    "        Console.WriteLine(\"‚úÖ RAG completed successfully\");\n",
    "        Console.WriteLine($\"   LLM response: {(llmResponse != null ? \"‚úì\" : \"‚úó\")}\");\n",
    "        Console.WriteLine($\"   Reranked chunks: {rerankedChunks.Count}\");\n",
    "\n",
    "        return new RagResult(llmResponse, rerankedChunks);\n",
    "    }\n",
    "    catch (Exception ex)\n",
    "    {\n",
    "        Console.WriteLine($\"‚ùå Error during RAG: {ex.Message}\");\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Usage - uses stored variables from cells 25 and 27\n",
    "if (demoSpace != null && voyageReranker != null && openaiLlm != null)\n",
    "{\n",
    "    Console.WriteLine(\"Testing Complete RAG Pipeline with Reranker + LLM\\n\");\n",
    "    \n",
    "    var testQuery = \"What is the vacation policy for employees?\";\n",
    "\n",
    "    var ragResult = await RagPipelineStreaming(\n",
    "        testQuery,\n",
    "        demoSpace.SpaceId,\n",
    "        voyageReranker.RerankerId,  // From cell 25 stored variable\n",
    "        openaiLlm.LlmId,             // From cell 27 stored variable\n",
    "        3\n",
    "    );\n",
    "\n",
    "    if (ragResult != null)\n",
    "    {\n",
    "        Console.WriteLine(\"\\nüéâ RAG pipeline completed!\");\n",
    "        Console.WriteLine($\"   LLM Response: {(ragResult.LlmResponse != null ? \"Available\" : \"None\")}\");\n",
    "        Console.WriteLine($\"   Chunks Retrieved: {ragResult.Chunks.Count}\");\n",
    "    }\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine(\"‚ö†Ô∏è  Cannot run RAG pipeline: missing space, reranker, or LLM\");\n",
    "    if (demoSpace == null) Console.WriteLine(\"   - Missing space: Please run cell 11 first\");\n",
    "    if (voyageReranker == null) Console.WriteLine(\"   - Missing reranker: Please run cell 25 first\");\n",
    "    if (openaiLlm == null) Console.WriteLine(\"   - Missing LLM: Please run cell 27 first\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "conclusion",
    "description": "Tutorial completion and next steps",
    "language_dependent": false,
    "notebook": "dotnet"
   },
   "source": [
    "## üéâ Congratulations! What You Built\n",
    "\n",
    "You've successfully built a complete **Retrieval-Augmented Generation (RAG) system** using GoodMem! Let's recap what you accomplished.\n",
    "\n",
    "### Components You Configured\n",
    "\n",
    "| Component | Purpose | Function |\n",
    "|-----------|---------|----------|\n",
    "| **Embedder** | Convert text to vectors | Transform documents into semantic embeddings |\n",
    "| **Space** | Organize and store documents | Logical container with chunking configuration |\n",
    "| **Memories** | Store searchable content | Documents chunked and indexed for retrieval |\n",
    "| **Reranker** | Improve search precision | Re-score results for better relevance |\n",
    "| **LLM** | Generate natural language | Create coherent answers from retrieved context |\n",
    "\n",
    "### The Complete RAG Pipeline\n",
    "\n",
    "```\n",
    "üìÑ Documents\n",
    "   ‚Üì Chunking (256 chars, 25 overlap)\n",
    "   ‚Üì Embedding (convert to vectors)\n",
    "üóÑÔ∏è  Vector Storage (GoodMem Space)\n",
    "   ‚Üì \n",
    "üîç User Query\n",
    "   ‚Üì Semantic Search (retrieve top-K)\n",
    "   ‚Üì Reranking (re-score for precision)\n",
    "   ‚Üì Context Selection (most relevant chunks)\n",
    "ü§ñ LLM Generation (synthesize answer)\n",
    "   ‚Üì\n",
    "‚ú® Natural Language Answer\n",
    "```\n",
    "\n",
    "### Key Concepts You Learned\n",
    "\n",
    "1. **Embedders**: Transform text into semantic vectors for similarity search\n",
    "2. **Spaces**: Logical containers for organizing and searching documents\n",
    "3. **Chunking**: Breaking documents into optimal sizes for retrieval\n",
    "4. **Semantic Search**: Finding conceptually similar content, not just keyword matches\n",
    "5. **Reranking**: Two-stage retrieval for better precision\n",
    "6. **Streaming API**: Real-time, memory-efficient result processing\n",
    "7. **RAG Architecture**: Combining retrieval and generation for accurate, grounded responses\n",
    "\n",
    "### Performance Improvements\n",
    "\n",
    "**Basic search** (retrieval only):\n",
    "- Fast retrieval using vector similarity\n",
    "- Good recall, but may include less relevant results\n",
    "\n",
    "**Enhanced RAG** (with reranker + LLM):\n",
    "- Reranker improves precision significantly\n",
    "- LLM synthesizes information from multiple chunks\n",
    "- Better user experience with natural language answers\n",
    "- Grounded in actual document content (no hallucinations)\n",
    "\n",
    "### Next Steps & Advanced Topics\n",
    "\n",
    "**Enhance Your RAG System**:\n",
    "- **Multiple embedders**: Combine different embedders for better coverage\n",
    "- **Custom chunking**: Tune chunk size/overlap for your content type\n",
    "- **Metadata filtering**: Add filters to narrow search by document type, date, etc.\n",
    "- **Hybrid search**: Combine semantic and keyword search\n",
    "- **Context augmentation**: Include surrounding chunks for better LLM context\n",
    "\n",
    "**Production Deployment**:\n",
    "- **Monitoring**: Track query latency, relevance scores, user feedback\n",
    "- **Scaling**: Horizontal scaling for high-traffic applications\n",
    "- **Cost optimization**: Balance quality vs. API costs\n",
    "- **Caching**: Cache frequent queries for faster responses\n",
    "- **Error handling**: Robust exception handling and retry logic\n",
    "\n",
    "**Advanced Features**:\n",
    "- **Multi-space search**: Query across multiple knowledge bases\n",
    "- **Query expansion**: Transform queries for better retrieval\n",
    "- **Result aggregation**: Combine and deduplicate results\n",
    "- **Streaming generation**: Progressive LLM responses for real-time UX\n",
    "- **Fine-tuning**: Customize models for your specific domain\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Documentation**: [https://docs.goodmem.ai](https://docs.goodmem.ai)\n",
    "- **Community**: Join discussions and share your implementations\n",
    "- **Examples**: Explore more advanced use cases and patterns\n",
    "\n",
    "---\n",
    "\n",
    "**Great job!** You now have a solid foundation for building production RAG systems with GoodMem. üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "polyglot-notebook",
   "pygments_lexer": "csharp",
   "version": "13.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
